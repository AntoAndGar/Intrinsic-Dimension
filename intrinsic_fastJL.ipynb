{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU is available\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision.models as models\n",
    "import numpy as np\n",
    "from torchvision import models, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.datasets import MNIST, CIFAR10\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    print(\"GPU is available\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"GPU is not available\")\n",
    "\n",
    "# add reproducibility stuff\n",
    "torch.manual_seed(42)\n",
    "torch.cuda.manual_seed_all(42)\n",
    "np.random.seed(42)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SparseWrap(nn.Module):\n",
    "    def __init__(self, module, intrinsic_dimension, device):\n",
    "        \"\"\"\n",
    "        Wrapper to estimate the intrinsic dimensionality of the\n",
    "        objective landscape for a specific task given a specific model\n",
    "        :param module: pytorch nn.Module\n",
    "        :param intrinsic_dimension: dimensionality within which we search for solution\n",
    "        :param device: cuda device id\n",
    "        \"\"\"\n",
    "        super(SparseWrap, self).__init__()\n",
    "\n",
    "        # Hide this from inspection by get_parameters()\n",
    "        self.m = [module]\n",
    "\n",
    "        self.name_base_localname = []\n",
    "\n",
    "        # Stores the initial value: \\theta_{0}^{D}\n",
    "        self.initial_value = dict()\n",
    "\n",
    "        # Stores the randomly generated projection matrix P\n",
    "        self.random_matrix = dict()\n",
    "\n",
    "        # Parameter vector that is updated, initialised with zeros as per text: \\theta^{d}\n",
    "        V = nn.Parameter(\n",
    "            torch.zeros((intrinsic_dimension, 1)).to(device, non_blocking=True)\n",
    "        )\n",
    "        self.register_parameter(\"V\", V)\n",
    "        v_size = (intrinsic_dimension,)\n",
    "\n",
    "        # Iterates over layers in the Neural Network\n",
    "        for name, param in module.named_parameters():\n",
    "            # If the parameter requires gradient update\n",
    "            if param.requires_grad:\n",
    "\n",
    "                # Saves the initial values of the initialised parameters from param.data and sets them to no grad.\n",
    "                # (initial values are the 'origin' of the search)\n",
    "                self.initial_value[name] = v0 = (\n",
    "                    param.clone()\n",
    "                    .detach()\n",
    "                    .requires_grad_(False)\n",
    "                    .to(device, non_blocking=True)\n",
    "                )\n",
    "\n",
    "                # If v0.size() is [4, 3], then below operation makes it [4, 3, v_size]\n",
    "                matrix_size = v0.size() + v_size\n",
    "\n",
    "                # Generates random projection matrices P, sets them to no grad\n",
    "                self.random_matrix[name] = (\n",
    "                    torch.randn(matrix_size, requires_grad=False)\n",
    "                    .to_sparse()\n",
    "                    .to(device, non_blocking=True)\n",
    "                    / intrinsic_dimension**0.5\n",
    "                )\n",
    "\n",
    "                # NOTE!: lines below are not clear!\n",
    "                base, localname = module, name\n",
    "                while \".\" in localname:\n",
    "                    prefix, localname = localname.split(\".\", 1)\n",
    "                    base = base.__getattr__(prefix)\n",
    "                self.name_base_localname.append((name, base, localname))\n",
    "\n",
    "        for name, base, localname in self.name_base_localname:\n",
    "            delattr(base, localname)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Iterate over the layers\n",
    "        for name, base, localname in self.name_base_localname:\n",
    "            # print(name)\n",
    "            # print(localname)\n",
    "\n",
    "            # Product between matrix P and \\theta^{d}\n",
    "            # print(\"random_matrix shape: \", self.random_matrix[name].shape)\n",
    "            # print(\"random_matrix: \", self.random_matrix[name])\n",
    "            # print(\"V shape: \", self.V.shape)\n",
    "\n",
    "            # print(\"initail value shape:\", self.initial_value[name].shape)\n",
    "            if len(self.random_matrix[name].shape) <= 2:\n",
    "                ray = torch.mm(self.random_matrix[name], self.V)\n",
    "            else:\n",
    "                ray = torch.bmm(\n",
    "                    self.random_matrix[name],\n",
    "                    self.V.broadcast_to(\n",
    "                        (\n",
    "                            self.random_matrix[name].shape[0],\n",
    "                            self.V.shape[0],\n",
    "                            self.V.shape[-1],\n",
    "                        )\n",
    "                    ),\n",
    "                )\n",
    "            # print(\"ray shape: \",ray.shape)\n",
    "\n",
    "            # Add the \\theta_{0}^{D} to P \\dot \\theta^{d}\n",
    "            param = torch.squeeze(ray, -1) + self.initial_value[name]\n",
    "            # print(\"param shape: \", param.shape)\n",
    "\n",
    "            setattr(base, localname, param)\n",
    "\n",
    "        # Pass through the model, by getting the module from a list self.m\n",
    "        module = self.m[0]\n",
    "        x = module(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fast_walsh_hadamard_torched(x, axis=0, normalize=False):\n",
    "    \"\"\"\n",
    "    Performs fast Walsh Hadamard transform\n",
    "    :param x:\n",
    "    :param axis:\n",
    "    :param normalize:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    orig_shape = x.size()\n",
    "    assert axis >= 0 and axis < len(\n",
    "        orig_shape\n",
    "    ), \"For a vector of shape %s, axis must be in [0, %d] but it is %d\" % (\n",
    "        orig_shape,\n",
    "        len(orig_shape) - 1,\n",
    "        axis,\n",
    "    )\n",
    "    h_dim = orig_shape[axis]\n",
    "    h_dim_exp = int(round(np.log(h_dim) / np.log(2)))\n",
    "    assert h_dim == 2**h_dim_exp, (\n",
    "        \"hadamard can only be computed over axis with size that is a power of two, but\"\n",
    "        \" chosen axis %d has size %d\" % (axis, h_dim)\n",
    "    )\n",
    "\n",
    "    working_shape_pre = [int(np.prod(orig_shape[:axis]))]  # prod of empty array is 1 :)\n",
    "    working_shape_post = [\n",
    "        int(np.prod(orig_shape[axis + 1 :]))\n",
    "    ]  # prod of empty array is 1 :)\n",
    "    working_shape_mid = [2] * h_dim_exp\n",
    "    working_shape = working_shape_pre + working_shape_mid + working_shape_post\n",
    "\n",
    "    ret = x.view(working_shape)\n",
    "\n",
    "    for ii in range(h_dim_exp):\n",
    "        dim = ii + 1\n",
    "        arrs = torch.chunk(ret, 2, dim=dim)\n",
    "        assert len(arrs) == 2\n",
    "        ret = torch.cat((arrs[0] + arrs[1], arrs[0] - arrs[1]), axis=dim)\n",
    "\n",
    "    if normalize:\n",
    "        ret = ret / torch.sqrt(float(h_dim))\n",
    "\n",
    "    ret = ret.view(orig_shape)\n",
    "\n",
    "    return ret\n",
    "\n",
    "\n",
    "def rademacher(shape, device=0):\n",
    "    \"\"\"Creates a random tensor of shape under the Rademacher distribution (P(x=1) == P(x=-1) == 0.5)\"\"\"\n",
    "    x = torch.empty(shape, device=device, requires_grad=False).random_(\n",
    "        0, 2\n",
    "    )  # Creates random tensor of 0 and 1\n",
    "    x[x == 0] = -1  # Turn the 0s into -1\n",
    "    return x\n",
    "\n",
    "\n",
    "def fastJL_vars(DD, d, device=0):\n",
    "    \"\"\"\n",
    "    Returns parameters for fast food transform\n",
    "    :param DD: desired dimension\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    epsilon = 0.1\n",
    "    ll = int(np.ceil(np.log2(d)))\n",
    "    LL = 2**ll\n",
    "\n",
    "    # random reflection given by the diagonal matrix D ∈ R^d×d where Dii are independent Rademacher random variables\n",
    "    D = torch.diag(rademacher(LL, device=device)).to(device, non_blocking=True)\n",
    "    D.requires_grad = False\n",
    "\n",
    "    n = np.log(60000)\n",
    "    k = int(np.ceil(n / epsilon**2))\n",
    "    # print(\"k: \", k)\n",
    "    # Pij ≡ bijxrij , where bij ∼ Bernoulli(q) and rij ∼ N (0, q−1) are independent random variables\n",
    "    q = min(n / epsilon * LL, 1)\n",
    "    B = torch.empty(\n",
    "        (k, LL), dtype=torch.float32, device=device, requires_grad=False\n",
    "    ).bernoulli_(q)\n",
    "\n",
    "    R = torch.empty(\n",
    "        (k, LL), dtype=torch.float32, device=device, requires_grad=False\n",
    "    ).normal_(0, 1 / q)\n",
    "\n",
    "    PP = torch.mul(B, R)\n",
    "    PP.requires_grad = False\n",
    "    PP.to(device, non_blocking=True)\n",
    "    # print(\"PP: \", PP.shape)\n",
    "\n",
    "    return [D, PP, LL]\n",
    "\n",
    "\n",
    "def fastJL_torched(x, DD, param_list=None, device=0):\n",
    "    \"\"\"\n",
    "    Fastfood transform\n",
    "    :param x: array of dd dimension\n",
    "    :param DD: desired dimension\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    dd = x.size(0)\n",
    "    # print(\"dd: \", dd)\n",
    "\n",
    "    if not param_list:\n",
    "\n",
    "        D, PP, LL = fastJL_vars(DD, dd, device=device)\n",
    "\n",
    "    else:\n",
    "\n",
    "        D, PP, LL = param_list\n",
    "\n",
    "    # Padd x if needed\n",
    "    dd_pad = F.pad(x, pad=(0, LL - dd), value=0, mode=\"constant\")\n",
    "\n",
    "    # From left to right (1/k)PH(Dx), where H is Walsh-Hadamard matrix\n",
    "    mul_1 = torch.mul(D, dd_pad)\n",
    "    # print(\"mul_1: \", mul_1.shape)\n",
    "\n",
    "    # (1/k)P(HDx)\n",
    "    mul_2 = fast_walsh_hadamard_torched(mul_1, 0, normalize=False)\n",
    "    # print(\"mul_2: \", mul_2.shape)\n",
    "\n",
    "    # (1/k)(PHDx)\n",
    "    mul_3 = torch.mm(PP, mul_2).flatten()\n",
    "    # print(\"mul_3: \", mul_3.shape)\n",
    "\n",
    "    ret = 1 / dd * mul_3[:DD]\n",
    "\n",
    "    return ret\n",
    "\n",
    "\n",
    "class FastJLWrapper(nn.Module):\n",
    "    def __init__(self, module, intrinsic_dimension, device):\n",
    "        \"\"\"\n",
    "        Wrapper to estimate the intrinsic dimensionality of the\n",
    "        objective landscape for a specific task given a specific model using FastJL transform\n",
    "        :param module: pytorch nn.Module\n",
    "        :param intrinsic_dimension: dimensionality within which we search for solution\n",
    "        :param device: cuda device id\n",
    "        \"\"\"\n",
    "        super(FastJLWrapper, self).__init__()\n",
    "\n",
    "        # Hide this from inspection by get_parameters()\n",
    "        self.m = [module]\n",
    "\n",
    "        self.name_base_localname = []\n",
    "\n",
    "        # Stores the initial value: \\theta_{0}^{D}\n",
    "        self.initial_value = dict()\n",
    "\n",
    "        # Fastfood parameters\n",
    "        self.fastJL_params = {}\n",
    "\n",
    "        # Parameter vector that is updated\n",
    "        # Initialised with zeros as per text: \\theta^{d}\n",
    "        V = nn.Parameter(\n",
    "            torch.zeros((intrinsic_dimension), device=device)\n",
    "        )  # .to(device))\n",
    "        self.register_parameter(\"V\", V)\n",
    "        V.to(device, non_blocking=True)\n",
    "\n",
    "        # Iterate over layers in the module\n",
    "        for name, param in module.named_parameters():\n",
    "            # If param requires grad update\n",
    "            if param.requires_grad:\n",
    "\n",
    "                # Saves the initial values of the initialised parameters from param.data and sets them to no grad.\n",
    "                # (initial values are the 'origin' of the search)\n",
    "                self.initial_value[name] = v0 = (\n",
    "                    param.clone()\n",
    "                    .detach()\n",
    "                    .requires_grad_(False)\n",
    "                    .to(device, non_blocking=True)\n",
    "                )\n",
    "\n",
    "                # Generate fastJL parameters\n",
    "                DD = np.prod(v0.size())\n",
    "                self.fastJL_params[name] = fastJL_vars(DD, V.size(0), device)\n",
    "\n",
    "                base, localname = module, name\n",
    "                while \".\" in localname:\n",
    "                    prefix, localname = localname.split(\".\", 1)\n",
    "                    base = base.__getattr__(prefix)\n",
    "                self.name_base_localname.append((name, base, localname))\n",
    "\n",
    "        for name, base, localname in self.name_base_localname:\n",
    "            delattr(base, localname)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Iterate over layers\n",
    "        for name, base, localname in self.name_base_localname:\n",
    "\n",
    "            init_shape = self.initial_value[name].size()\n",
    "            # print(\"init_shape: \", init_shape)\n",
    "            DD = np.prod(init_shape)\n",
    "            # print(\"DD: \", DD)\n",
    "\n",
    "            # FastJL transform replace dense P\n",
    "            ray = fastJL_torched(self.V, DD, self.fastJL_params[name]).view(init_shape)\n",
    "\n",
    "            param = self.initial_value[name] + ray\n",
    "\n",
    "            setattr(base, localname, param)\n",
    "\n",
    "        # Pass through the model, by getting hte module from a list self.m\n",
    "        module = self.m[0]\n",
    "        x = module(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 128\n",
    "DATASET_NAME = \"MNIST\"\n",
    "\n",
    "img_transform = transforms.Compose([transforms.ToTensor()])\n",
    "\n",
    "train_dataset = None\n",
    "test_dataset = None\n",
    "if DATASET_NAME == \"MNIST\":\n",
    "    train_dataset = MNIST(\n",
    "        root=\"./data/MNIST\", download=True, train=True, transform=img_transform\n",
    "    )\n",
    "    test_dataset = MNIST(\n",
    "        root=\"./data/MNIST\", download=True, train=False, transform=img_transform\n",
    "    )\n",
    "elif DATASET_NAME == \"CIFAR10\":\n",
    "    train_dataset = CIFAR10(\n",
    "        root=\"./data/CIFAR10\", download=True, train=True, transform=img_transform\n",
    "    )\n",
    "    test_dataset = CIFAR10(\n",
    "        root=\"./data/CIFAR10\", download=True, train=False, transform=img_transform\n",
    "    )\n",
    "else:\n",
    "    raise Exception(\"Name of dataset not in: [MNIST, CIFAR10]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "coloraxis": "coloraxis",
         "hovertemplate": "x: %{x}<br>y: %{y}<br>color: %{z}<extra></extra>",
         "name": "0",
         "type": "heatmap",
         "xaxis": "x",
         "yaxis": "y",
         "z": [
          [
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0
          ],
          [
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0
          ],
          [
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0
          ],
          [
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0
          ],
          [
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0
          ],
          [
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           3,
           18,
           18,
           18,
           126,
           136,
           175,
           26,
           166,
           255,
           247,
           127,
           0,
           0,
           0,
           0
          ],
          [
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           30,
           36,
           94,
           154,
           170,
           253,
           253,
           253,
           253,
           253,
           225,
           172,
           253,
           242,
           195,
           64,
           0,
           0,
           0,
           0
          ],
          [
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           49,
           238,
           253,
           253,
           253,
           253,
           253,
           253,
           253,
           253,
           251,
           93,
           82,
           82,
           56,
           39,
           0,
           0,
           0,
           0,
           0
          ],
          [
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           18,
           219,
           253,
           253,
           253,
           253,
           253,
           198,
           182,
           247,
           241,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0
          ],
          [
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           80,
           156,
           107,
           253,
           253,
           205,
           11,
           0,
           43,
           154,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0
          ],
          [
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           14,
           1,
           154,
           253,
           90,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0
          ],
          [
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           139,
           253,
           190,
           2,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0
          ],
          [
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           11,
           190,
           253,
           70,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0
          ],
          [
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           35,
           241,
           225,
           160,
           108,
           1,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0
          ],
          [
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           81,
           240,
           253,
           253,
           119,
           25,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0
          ],
          [
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           45,
           186,
           253,
           253,
           150,
           27,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0
          ],
          [
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           16,
           93,
           252,
           253,
           187,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0
          ],
          [
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           249,
           253,
           249,
           64,
           0,
           0,
           0,
           0,
           0,
           0,
           0
          ],
          [
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           46,
           130,
           183,
           253,
           253,
           207,
           2,
           0,
           0,
           0,
           0,
           0,
           0,
           0
          ],
          [
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           39,
           148,
           229,
           253,
           253,
           253,
           250,
           182,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0
          ],
          [
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           24,
           114,
           221,
           253,
           253,
           253,
           253,
           201,
           78,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0
          ],
          [
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           23,
           66,
           213,
           253,
           253,
           253,
           253,
           198,
           81,
           2,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0
          ],
          [
           0,
           0,
           0,
           0,
           0,
           0,
           18,
           171,
           219,
           253,
           253,
           253,
           253,
           195,
           80,
           9,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0
          ],
          [
           0,
           0,
           0,
           0,
           55,
           172,
           226,
           253,
           253,
           253,
           253,
           244,
           133,
           11,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0
          ],
          [
           0,
           0,
           0,
           0,
           136,
           253,
           253,
           253,
           212,
           135,
           132,
           16,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0
          ],
          [
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0
          ],
          [
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0
          ],
          [
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0
          ]
         ]
        }
       ],
       "layout": {
        "coloraxis": {
         "colorscale": [
          [
           0,
           "#0d0887"
          ],
          [
           0.1111111111111111,
           "#46039f"
          ],
          [
           0.2222222222222222,
           "#7201a8"
          ],
          [
           0.3333333333333333,
           "#9c179e"
          ],
          [
           0.4444444444444444,
           "#bd3786"
          ],
          [
           0.5555555555555556,
           "#d8576b"
          ],
          [
           0.6666666666666666,
           "#ed7953"
          ],
          [
           0.7777777777777778,
           "#fb9f3a"
          ],
          [
           0.8888888888888888,
           "#fdca26"
          ],
          [
           1,
           "#f0f921"
          ]
         ]
        },
        "margin": {
         "t": 60
        },
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "xaxis": {
         "anchor": "y",
         "constrain": "domain",
         "domain": [
          0,
          1
         ],
         "scaleanchor": "y"
        },
        "yaxis": {
         "anchor": "x",
         "autorange": "reversed",
         "constrain": "domain",
         "domain": [
          0,
          1
         ]
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if DATASET_NAME == \"MNIST\":\n",
    "    channel_in = 1\n",
    "    input_height = 28\n",
    "    input_width = 28\n",
    "    input_dim = input_height * input_width * channel_in\n",
    "    output_dim = 10\n",
    "    idx = 0  # @param {type:\"slider\", min:0, max:59999, step:1}\n",
    "else:\n",
    "    channel_in = 3\n",
    "    input_height = 32\n",
    "    input_width = 32\n",
    "    input_dim = input_height * input_width * channel_in\n",
    "    output_dim = 10\n",
    "    idx = 0  # @param {type:\"slider\", min:0, max:49999, step:1}\n",
    "\n",
    "px.imshow(train_dataset.data[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class for a Fully Connected Network\n",
    "class FullyConnectedNetwork(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim, num_layers):\n",
    "        super(FullyConnectedNetwork, self).__init__()\n",
    "        self.num_layers = num_layers\n",
    "        self.fc_in = nn.Linear(input_dim, hidden_dim)\n",
    "        if num_layers > 0:\n",
    "            self.fcs = nn.ModuleList(\n",
    "                [nn.Linear(hidden_dim, hidden_dim) for _ in range(num_layers)]\n",
    "            )\n",
    "        self.fc_out = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.flatten(x, start_dim=1)\n",
    "        x = F.relu(self.fc_in(x))\n",
    "        if self.num_layers > 0:\n",
    "            for fc in self.fcs:\n",
    "                x = F.relu(fc(x))\n",
    "        x = self.fc_out(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class for Standard LeNet Network, reference http://vision.stanford.edu/cs598_spring07/papers/Lecun98.pdf with some modification to follow the same number of parameters as the main paper for the task does\n",
    "class LeNet(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim, dataset=\"mnist\"):\n",
    "        super(LeNet, self).__init__()\n",
    "        # 6 kernels 5x5\n",
    "        self.conv1 = nn.Conv2d(\n",
    "            input_dim,\n",
    "            6,\n",
    "            5,\n",
    "            padding=\"valid\",\n",
    "        )\n",
    "        # max-pooling over 2x2\n",
    "        self.pool1 = nn.MaxPool2d(2, stride=2)\n",
    "        # 16 kernels 5x5\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5, padding=\"valid\")\n",
    "        # max-pooling over 2x2\n",
    "        self.pool2 = nn.MaxPool2d(2, stride=2)\n",
    "        # 120 kernels 4x4 to match the dimensionality of the fully connected network\n",
    "        self.conv3 = nn.Conv2d(\n",
    "            16,\n",
    "            120,\n",
    "            5 if dataset == \"cifar10\" else 4,\n",
    "        )\n",
    "        # 120 fully connected neurons, too many parameter in this case w.r.t. the paper\n",
    "        # self.fc1 = nn.Linear(16 * 5 * 5, 120,)\n",
    "        self.flat = nn.Flatten(start_dim=1)\n",
    "        # 84 fully connected neurons\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        # 10 fully connected neurons\n",
    "        self.fc3 = nn.Linear(\n",
    "            84,\n",
    "            output_dim,\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x = x.view(-1, 1, 28, 28)\n",
    "        #print(x.shape)\n",
    "        x = self.conv1(x)\n",
    "        #print(x.shape)\n",
    "        x = self.pool1(F.relu(x))\n",
    "        #print(x.shape)\n",
    "        x = self.pool2(F.relu(self.conv2(x)))\n",
    "        #print(x.shape)\n",
    "        x = F.relu(self.conv3(x))\n",
    "        x = self.flat(x)\n",
    "        # x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' class Untied_LeNet(nn.Module):\\n    def __init__(self, input_dim, output_dim):\\n        super(Untied_LeNet, self).__init__()\\n        # 6 kernels 5x5\\n        self.conv1 = LocallyConnected2d(input_dim, 6, (24,24), 5)\\n        # max-pooling over 2x2\\n        self.pool1 = nn.MaxPool2d(2, stride=2)\\n        # 16 kernels 5x5\\n        self.conv2 = LocallyConnected2d(6, 16, (8,8), 5)\\n        # max-pooling over 2x2\\n        self.pool2 = nn.MaxPool2d(2, stride=2)\\n        # 120 kernels 4x4 to match the dimensionality of the fully connected network\\n        self.conv3 = LocallyConnected2d(16, 120, (1,1), 4)\\n        # 120 fully connected neurons, too many parameter in this case w.r.t. the paper\\n        #self.fc1 = nn.Linear(16 * 5 * 5, 120,)\\n        self.flat = nn.Flatten(start_dim=1)\\n        # 84 fully connected neurons\\n        self.fc2 = nn.Linear(120, 84)\\n        # 10 fully connected neurons\\n        self.fc3 = nn.Linear(84, output_dim,)\\n\\n    def forward(self, x):\\n        #x = x.view(-1, 1, 28, 28)\\n        x = self.pool1(F.relu(self.conv1(x)))\\n        x = self.pool2(F.relu(self.conv2(x)))\\n        x = F.relu(self.conv3(x))\\n        x = self.flat(x)\\n        #x = F.relu(self.fc1(x))\\n        x = F.relu(self.fc2(x))\\n        x = self.fc3(x)\\n        return x '"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch.nn.modules.utils import _pair\n",
    "\n",
    "# from https://discuss.pytorch.org/t/locally-connected-layers/26979\n",
    "class LocallyConnected2d(nn.Module):\n",
    "    def __init__(\n",
    "        self, in_channels, out_channels, output_size, kernel_size, stride=1, bias=True\n",
    "    ):\n",
    "        super(LocallyConnected2d, self).__init__()\n",
    "        output_size = _pair(output_size)\n",
    "        self.weight = nn.Parameter(\n",
    "            nn.init.kaiming_normal_(\n",
    "                torch.randn(\n",
    "                    1,\n",
    "                    out_channels,\n",
    "                    in_channels,\n",
    "                    output_size[0],\n",
    "                    output_size[1],\n",
    "                    kernel_size**2,\n",
    "                ),\n",
    "                nonlinearity=\"relu\",\n",
    "            )\n",
    "        )\n",
    "        if bias:\n",
    "            self.bias = nn.Parameter(\n",
    "                nn.init.kaiming_normal_(\n",
    "                    torch.randn(1, out_channels, output_size[0], output_size[1]),\n",
    "                    nonlinearity=\"relu\",\n",
    "                )\n",
    "            )\n",
    "        else:\n",
    "            self.register_parameter(\"bias\", None)\n",
    "        self.kernel_size = _pair(kernel_size)\n",
    "        self.stride = _pair(stride)\n",
    "\n",
    "    def forward(self, x):\n",
    "        _, c, h, w = x.size()\n",
    "        kh, kw = self.kernel_size\n",
    "        dh, dw = self.stride\n",
    "        x = x.unfold(2, kh, dh).unfold(3, kw, dw)\n",
    "        x = x.contiguous().view(*x.size()[:-2], -1)\n",
    "        # Sum in in_channel and kernel_size dims\n",
    "        out = (x.unsqueeze(1) * self.weight).sum([2, -1])\n",
    "        if self.bias is not None:\n",
    "            out += self.bias\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class for general Untied LeNet Network\n",
    "class Untied_LeNet(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim, input_height, input_width):\n",
    "        super(Untied_LeNet, self).__init__()\n",
    "        # 6 kernels 5x5, output size 24x24 MNIST, output size 28x28 CIFAR10\n",
    "        self.kernel_size = 5\n",
    "        self.pool_kernel_size = 2\n",
    "        self.out_conv1 = (\n",
    "            input_height - (self.kernel_size - 1),\n",
    "            input_width - (self.kernel_size - 1),\n",
    "        )\n",
    "        self.conv1 = LocallyConnected2d(input_dim, 6, self.out_conv1, self.kernel_size)\n",
    "        # max-pooling over 2x2\n",
    "        self.pool1 = nn.MaxPool2d(self.pool_kernel_size, stride=2)\n",
    "        # 16 kernels 5x5 output size 8x8, output size 10x10 CIFAR10\n",
    "        self.out_conv2 = (\n",
    "            int(self.out_conv1[0] / self.pool_kernel_size) - (self.kernel_size - 1),\n",
    "            int(self.out_conv1[1] / self.pool_kernel_size) - (self.kernel_size - 1),\n",
    "        )\n",
    "        self.conv2 = LocallyConnected2d(6, 16, self.out_conv2, self.kernel_size)\n",
    "        # max-pooling over 2x2\n",
    "        self.pool2 = nn.MaxPool2d(self.pool_kernel_size, stride=2)\n",
    "        # 120 kernels 4x4 to match the dimensionality of the fully connected network and obtain an output size of 1x1 for MNIST and kernels 5x5 for CIFAR10\n",
    "        self.conv3 = LocallyConnected2d(\n",
    "            16, 120, (1, 1), int(self.out_conv2[0] / self.pool_kernel_size)\n",
    "        )\n",
    "        # 120 fully connected neurons, too many parameter in this case w.r.t. the paper\n",
    "        # self.fc1 = nn.Linear(16 * 5 * 5, 120,)\n",
    "        self.flat = nn.Flatten(start_dim=1)\n",
    "        # 84 fully connected neurons\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        # 10 fully connected neurons\n",
    "        self.fc3 = nn.Linear(\n",
    "            84,\n",
    "            output_dim,\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x = x.view(-1, 1, 28, 28)\n",
    "        x = self.pool1(F.relu(self.conv1(x)))\n",
    "        x = self.pool2(F.relu(self.conv2(x)))\n",
    "        x = F.relu(self.conv3(x))\n",
    "        x = self.flat(x)\n",
    "        # x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class for FC-LeNet Network\n",
    "class FcLeNet(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super(FcLeNet, self).__init__()\n",
    "        # 6 kernels 5x5\n",
    "        self.fcconv1 = nn.Linear(input_dim, 3456)\n",
    "        # max-pooling over 2x2\n",
    "        self.pool1 = nn.MaxPool2d(2, stride=2)\n",
    "        # 16 kernels 5x5\n",
    "        self.fcconv2 = nn.Linear(864, 1024)\n",
    "        # max-pooling over 2x2\n",
    "        self.pool2 = nn.MaxPool2d(2, stride=2)\n",
    "        # 120 kernels 4x4 to match the dimensionality of the fully connected network\n",
    "        self.fcconv3 = nn.Linear(256, 120)\n",
    "        # 120 fully connected neurons, too many parameter in this case w.r.t. the paper\n",
    "        # self.fc1 = nn.Linear(16 * 5 * 5, 120,)\n",
    "        self.flat = nn.Flatten(start_dim=1)\n",
    "        # 84 fully connected neurons\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        # 10 fully connected neurons\n",
    "        self.fc3 = nn.Linear(\n",
    "            84,\n",
    "            output_dim,\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.flatten(x, start_dim=1)\n",
    "        x = self.pool1(F.relu(self.fcconv1(x)).view(-1, 6, 24, 24))\n",
    "        x = self.flat(x)\n",
    "        x = self.pool2(F.relu(self.fcconv2(x)).view(-1, 16, 8, 8))\n",
    "        x = self.flat(x)\n",
    "        x = F.relu(self.fcconv3(x))\n",
    "        # x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class for general FCTied-LeNet\n",
    "class FCTied_LeNet(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim, input_height, input_width):\n",
    "        super(FCTied_LeNet, self).__init__()\n",
    "        # 6 kernels (2*H-1)x(2*H-1)\n",
    "        self.conv1 = nn.Conv2d(\n",
    "            input_dim,\n",
    "            6,\n",
    "            2 * input_height - 1,\n",
    "            padding=\"same\",\n",
    "        )\n",
    "        # max-pooling over 2x2\n",
    "        self.pool1 = nn.MaxPool2d(2, stride=2)\n",
    "        # 16 kernels (H-1)x(H-1)\n",
    "        self.conv2 = nn.Conv2d(6, 16, input_height - 1, padding=\"same\")\n",
    "        # max-pooling over 2x2\n",
    "        self.pool2 = nn.MaxPool2d(2, stride=2)\n",
    "        # 120 kernels 7x7 to match the dimensionality of the fully connected network\n",
    "        self.conv3 = nn.Conv2d(\n",
    "            16,\n",
    "            120,\n",
    "            int(input_height / 4),  # TODO: check if this is correct for cifar10\n",
    "        )\n",
    "        # 120 fully connected neurons, too many parameter in this case w.r.t. the paper\n",
    "        # self.fc1 = nn.Linear(16 * 5 * 5, 120,)\n",
    "        self.flat = nn.Flatten(start_dim=1)\n",
    "        # 84 fully connected neurons\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        # 10 fully connected neurons\n",
    "        self.fc3 = nn.Linear(\n",
    "            84,\n",
    "            output_dim,\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x = x.view(-1, 1, 28, 28)\n",
    "        x = self.pool1(F.relu(self.conv1(x)))\n",
    "        x = self.pool2(F.relu(self.conv2(x)))\n",
    "        x = F.relu(self.conv3(x))\n",
    "        x = self.flat(x)\n",
    "        # x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of parameters:  199210\n"
     ]
    }
   ],
   "source": [
    "hidden_dim = 200\n",
    "num_layers = 1\n",
    "model = FullyConnectedNetwork(input_dim, hidden_dim, output_dim, num_layers)\n",
    "model.to(device)\n",
    "\n",
    "num_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(\"Number of parameters: \", num_params)\n",
    "\n",
    "# save information to file\n",
    "# with open('results.txt', 'a') as f:\n",
    "#     f.write(\"\\n##############################################\")\n",
    "#     f.write(f\"\\nNumber_of_parameters: {num_params}\")\n",
    "#     f.write(f\"\\nhidden_dim: {hidden_dim}\")\n",
    "#     f.write(f\"\\nnum_layers: {num_layers}\")\n",
    "# f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FullyConnectedNetwork(\n",
      "  (fc_in): Linear(in_features=784, out_features=200, bias=True)\n",
      "  (fcs): ModuleList(\n",
      "    (0): Linear(in_features=200, out_features=200, bias=True)\n",
      "  )\n",
      "  (fc_out): Linear(in_features=200, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "modules = [module for module in model.modules()]\n",
    "# Print Model Summary\n",
    "print(modules[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of parameters: 44426\n"
     ]
    }
   ],
   "source": [
    "model = LeNet(channel_in, output_dim)\n",
    "model.to(device)\n",
    "\n",
    "num_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(\"Number of parameters: %d\" % num_params)\n",
    "\n",
    "# with open(\"results.txt\", \"a\") as f:\n",
    "#     f.write(\"\\n##############################################\")\n",
    "#     f.write(f\"\\nNumber_of_parameters: {num_params}\")\n",
    "#     f.write(\"\\ntype: LeNet\")\n",
    "# f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LeNet(\n",
      "  (conv1): Conv2d(3, 6, kernel_size=(5, 5), stride=(1, 1), padding=valid)\n",
      "  (pool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1), padding=valid)\n",
      "  (pool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (conv3): Conv2d(16, 120, kernel_size=(4, 4), stride=(1, 1))\n",
      "  (flat): Flatten(start_dim=1, end_dim=-1)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "modules = [module for module in model.modules()]\n",
    "# Print Model Summary\n",
    "print(modules[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of parameters: 658238\n"
     ]
    }
   ],
   "source": [
    "model = Untied_LeNet(channel_in, output_dim, input_height, input_width)\n",
    "model.to(device)\n",
    "\n",
    "num_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(\"Number of parameters: %d\" % num_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of parameters: 3640574\n"
     ]
    }
   ],
   "source": [
    "model = FcLeNet(input_dim, output_dim)\n",
    "model.to(device)\n",
    "\n",
    "num_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(\"Number of parameters: %d\" % num_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FcLeNet(\n",
      "  (fcconv1): Linear(in_features=784, out_features=3456, bias=True)\n",
      "  (pool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (fcconv2): Linear(in_features=864, out_features=1024, bias=True)\n",
      "  (pool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (fcconv3): Linear(in_features=256, out_features=120, bias=True)\n",
      "  (flat): Flatten(start_dim=1, end_dim=-1)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "modules = [module for module in model.modules()]\n",
    "# Print Model Summary\n",
    "print(modules[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of parameters: 193370\n"
     ]
    }
   ],
   "source": [
    "model = FCTied_LeNet(channel_in, output_dim, input_height, input_width)\n",
    "model.to(device)\n",
    "\n",
    "num_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(\"Number of parameters: %d\" % num_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of parameters: 150\n"
     ]
    }
   ],
   "source": [
    "intrinsic_dim = 150\n",
    "model_intrinsic = SparseWrap(model, intrinsic_dimension=intrinsic_dim, device=device)\n",
    "num_params_intrinsic = sum(\n",
    "    p.numel() for p in model_intrinsic.parameters() if p.requires_grad\n",
    ")\n",
    "print(\"Number of parameters: %d\" % num_params_intrinsic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of parameters: 500\n"
     ]
    }
   ],
   "source": [
    "intrinsic_dim = 500\n",
    "model_intrinsic = FastJLWrapper(model, intrinsic_dimension=intrinsic_dim, device=device)\n",
    "num_params_intrinsic = sum(\n",
    "    p.numel() for p in model_intrinsic.parameters() if p.requires_grad\n",
    ")\n",
    "print(\"Number of parameters: %d\" % num_params_intrinsic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/469 [00:01<?, ?it/s]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 4.00 GiB (GPU 0; 8.00 GiB total capacity; 5.27 GiB already allocated; 1.29 GiB free; 5.35 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32md:\\Antonio\\Sapienza\\Deep Learning & AAI\\Intrinsic_Dimension\\Intrinsic-Dimension\\intrinsic_sparse copy.ipynb Cella 22\u001b[0m in \u001b[0;36m<cell line: 96>\u001b[1;34m()\u001b[0m\n\u001b[0;32m    <a href='vscode-notebook-cell:/d%3A/Antonio/Sapienza/Deep%20Learning%20%26%20AAI/Intrinsic_Dimension/Intrinsic-Dimension/intrinsic_sparse%20copy.ipynb#X30sZmlsZQ%3D%3D?line=114'>115</a>\u001b[0m best_acc, best_epoch \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m, \u001b[39m0\u001b[39m\n\u001b[0;32m    <a href='vscode-notebook-cell:/d%3A/Antonio/Sapienza/Deep%20Learning%20%26%20AAI/Intrinsic_Dimension/Intrinsic-Dimension/intrinsic_sparse%20copy.ipynb#X30sZmlsZQ%3D%3D?line=115'>116</a>\u001b[0m \u001b[39mfor\u001b[39;00m epoch \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m1\u001b[39m, \u001b[39m101\u001b[39m):\n\u001b[1;32m--> <a href='vscode-notebook-cell:/d%3A/Antonio/Sapienza/Deep%20Learning%20%26%20AAI/Intrinsic_Dimension/Intrinsic-Dimension/intrinsic_sparse%20copy.ipynb#X30sZmlsZQ%3D%3D?line=116'>117</a>\u001b[0m     train(model_intrinsic, train_dataloader, optimizer, epoch)\n\u001b[0;32m    <a href='vscode-notebook-cell:/d%3A/Antonio/Sapienza/Deep%20Learning%20%26%20AAI/Intrinsic_Dimension/Intrinsic-Dimension/intrinsic_sparse%20copy.ipynb#X30sZmlsZQ%3D%3D?line=117'>118</a>\u001b[0m     accuracy \u001b[39m=\u001b[39m test(model_intrinsic, test_dataloader)\n\u001b[0;32m    <a href='vscode-notebook-cell:/d%3A/Antonio/Sapienza/Deep%20Learning%20%26%20AAI/Intrinsic_Dimension/Intrinsic-Dimension/intrinsic_sparse%20copy.ipynb#X30sZmlsZQ%3D%3D?line=118'>119</a>\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mValidation Accuracy: \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(accuracy))\n",
      "\u001b[1;32md:\\Antonio\\Sapienza\\Deep Learning & AAI\\Intrinsic_Dimension\\Intrinsic-Dimension\\intrinsic_sparse copy.ipynb Cella 22\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(model, train_loader, optimizer, epoch)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Antonio/Sapienza/Deep%20Learning%20%26%20AAI/Intrinsic_Dimension/Intrinsic-Dimension/intrinsic_sparse%20copy.ipynb#X30sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m \u001b[39mfor\u001b[39;00m batch_idx, (data, target) \u001b[39min\u001b[39;00m tqdm_iterator:\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Antonio/Sapienza/Deep%20Learning%20%26%20AAI/Intrinsic_Dimension/Intrinsic-Dimension/intrinsic_sparse%20copy.ipynb#X30sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m     data, target \u001b[39m=\u001b[39m data\u001b[39m.\u001b[39mto(device, non_blocking\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m), target\u001b[39m.\u001b[39mto(\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Antonio/Sapienza/Deep%20Learning%20%26%20AAI/Intrinsic_Dimension/Intrinsic-Dimension/intrinsic_sparse%20copy.ipynb#X30sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m         device, non_blocking\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Antonio/Sapienza/Deep%20Learning%20%26%20AAI/Intrinsic_Dimension/Intrinsic-Dimension/intrinsic_sparse%20copy.ipynb#X30sZmlsZQ%3D%3D?line=24'>25</a>\u001b[0m     )\n\u001b[1;32m---> <a href='vscode-notebook-cell:/d%3A/Antonio/Sapienza/Deep%20Learning%20%26%20AAI/Intrinsic_Dimension/Intrinsic-Dimension/intrinsic_sparse%20copy.ipynb#X30sZmlsZQ%3D%3D?line=25'>26</a>\u001b[0m     output \u001b[39m=\u001b[39m model(data)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Antonio/Sapienza/Deep%20Learning%20%26%20AAI/Intrinsic_Dimension/Intrinsic-Dimension/intrinsic_sparse%20copy.ipynb#X30sZmlsZQ%3D%3D?line=26'>27</a>\u001b[0m     loss \u001b[39m=\u001b[39m F\u001b[39m.\u001b[39mcross_entropy(output, target)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Antonio/Sapienza/Deep%20Learning%20%26%20AAI/Intrinsic_Dimension/Intrinsic-Dimension/intrinsic_sparse%20copy.ipynb#X30sZmlsZQ%3D%3D?line=27'>28</a>\u001b[0m     model\u001b[39m.\u001b[39mzero_grad(set_to_none\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "File \u001b[1;32md:\\Antonio\\python\\lib\\site-packages\\torch\\nn\\modules\\module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1106\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1107\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1108\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1109\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1110\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1111\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1112\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "\u001b[1;32md:\\Antonio\\Sapienza\\Deep Learning & AAI\\Intrinsic_Dimension\\Intrinsic-Dimension\\intrinsic_sparse copy.ipynb Cella 22\u001b[0m in \u001b[0;36mFastJLWrapper.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    <a href='vscode-notebook-cell:/d%3A/Antonio/Sapienza/Deep%20Learning%20%26%20AAI/Intrinsic_Dimension/Intrinsic-Dimension/intrinsic_sparse%20copy.ipynb#X30sZmlsZQ%3D%3D?line=190'>191</a>\u001b[0m DD \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mprod(init_shape)\n\u001b[0;32m    <a href='vscode-notebook-cell:/d%3A/Antonio/Sapienza/Deep%20Learning%20%26%20AAI/Intrinsic_Dimension/Intrinsic-Dimension/intrinsic_sparse%20copy.ipynb#X30sZmlsZQ%3D%3D?line=191'>192</a>\u001b[0m \u001b[39m# print(\"DD: \", DD)\u001b[39;00m\n\u001b[0;32m    <a href='vscode-notebook-cell:/d%3A/Antonio/Sapienza/Deep%20Learning%20%26%20AAI/Intrinsic_Dimension/Intrinsic-Dimension/intrinsic_sparse%20copy.ipynb#X30sZmlsZQ%3D%3D?line=192'>193</a>\u001b[0m \n\u001b[0;32m    <a href='vscode-notebook-cell:/d%3A/Antonio/Sapienza/Deep%20Learning%20%26%20AAI/Intrinsic_Dimension/Intrinsic-Dimension/intrinsic_sparse%20copy.ipynb#X30sZmlsZQ%3D%3D?line=193'>194</a>\u001b[0m \u001b[39m# FastJL transform replace dense P\u001b[39;00m\n\u001b[1;32m--> <a href='vscode-notebook-cell:/d%3A/Antonio/Sapienza/Deep%20Learning%20%26%20AAI/Intrinsic_Dimension/Intrinsic-Dimension/intrinsic_sparse%20copy.ipynb#X30sZmlsZQ%3D%3D?line=194'>195</a>\u001b[0m ray \u001b[39m=\u001b[39m fastJL_torched(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mV, DD, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfastJL_params[name])\u001b[39m.\u001b[39mview(init_shape)\n\u001b[0;32m    <a href='vscode-notebook-cell:/d%3A/Antonio/Sapienza/Deep%20Learning%20%26%20AAI/Intrinsic_Dimension/Intrinsic-Dimension/intrinsic_sparse%20copy.ipynb#X30sZmlsZQ%3D%3D?line=196'>197</a>\u001b[0m param \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39minitial_value[name] \u001b[39m+\u001b[39m ray\n\u001b[0;32m    <a href='vscode-notebook-cell:/d%3A/Antonio/Sapienza/Deep%20Learning%20%26%20AAI/Intrinsic_Dimension/Intrinsic-Dimension/intrinsic_sparse%20copy.ipynb#X30sZmlsZQ%3D%3D?line=198'>199</a>\u001b[0m \u001b[39msetattr\u001b[39m(base, localname, param)\n",
      "\u001b[1;32md:\\Antonio\\Sapienza\\Deep Learning & AAI\\Intrinsic_Dimension\\Intrinsic-Dimension\\intrinsic_sparse copy.ipynb Cella 22\u001b[0m in \u001b[0;36mfastJL_torched\u001b[1;34m(x, DD, param_list, device)\u001b[0m\n\u001b[0;32m    <a href='vscode-notebook-cell:/d%3A/Antonio/Sapienza/Deep%20Learning%20%26%20AAI/Intrinsic_Dimension/Intrinsic-Dimension/intrinsic_sparse%20copy.ipynb#X30sZmlsZQ%3D%3D?line=108'>109</a>\u001b[0m dd_pad \u001b[39m=\u001b[39m F\u001b[39m.\u001b[39mpad(x, pad\u001b[39m=\u001b[39m(\u001b[39m0\u001b[39m, LL \u001b[39m-\u001b[39m dd), value\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m, mode\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mconstant\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    <a href='vscode-notebook-cell:/d%3A/Antonio/Sapienza/Deep%20Learning%20%26%20AAI/Intrinsic_Dimension/Intrinsic-Dimension/intrinsic_sparse%20copy.ipynb#X30sZmlsZQ%3D%3D?line=110'>111</a>\u001b[0m \u001b[39m# From left to right (1/k)PH(Dx), where H is Walsh-Hadamard matrix\u001b[39;00m\n\u001b[1;32m--> <a href='vscode-notebook-cell:/d%3A/Antonio/Sapienza/Deep%20Learning%20%26%20AAI/Intrinsic_Dimension/Intrinsic-Dimension/intrinsic_sparse%20copy.ipynb#X30sZmlsZQ%3D%3D?line=111'>112</a>\u001b[0m mul_1 \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49mmul(D, dd_pad)\n\u001b[0;32m    <a href='vscode-notebook-cell:/d%3A/Antonio/Sapienza/Deep%20Learning%20%26%20AAI/Intrinsic_Dimension/Intrinsic-Dimension/intrinsic_sparse%20copy.ipynb#X30sZmlsZQ%3D%3D?line=112'>113</a>\u001b[0m \u001b[39m# print(\"mul_1: \", mul_1.shape)\u001b[39;00m\n\u001b[0;32m    <a href='vscode-notebook-cell:/d%3A/Antonio/Sapienza/Deep%20Learning%20%26%20AAI/Intrinsic_Dimension/Intrinsic-Dimension/intrinsic_sparse%20copy.ipynb#X30sZmlsZQ%3D%3D?line=113'>114</a>\u001b[0m \n\u001b[0;32m    <a href='vscode-notebook-cell:/d%3A/Antonio/Sapienza/Deep%20Learning%20%26%20AAI/Intrinsic_Dimension/Intrinsic-Dimension/intrinsic_sparse%20copy.ipynb#X30sZmlsZQ%3D%3D?line=114'>115</a>\u001b[0m \u001b[39m# (1/k)P(HDx)\u001b[39;00m\n\u001b[0;32m    <a href='vscode-notebook-cell:/d%3A/Antonio/Sapienza/Deep%20Learning%20%26%20AAI/Intrinsic_Dimension/Intrinsic-Dimension/intrinsic_sparse%20copy.ipynb#X30sZmlsZQ%3D%3D?line=115'>116</a>\u001b[0m mul_2 \u001b[39m=\u001b[39m fast_walsh_hadamard_torched(mul_1, \u001b[39m0\u001b[39m, normalize\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 4.00 GiB (GPU 0; 8.00 GiB total capacity; 5.27 GiB already allocated; 1.29 GiB free; 5.35 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ]
    }
   ],
   "source": [
    "# torch.autograd.set_detect_anomaly(True) #this line can have huge performance impact\n",
    "# train the model\n",
    "from logging import raiseExceptions\n",
    "\n",
    "# training step\n",
    "\n",
    "\n",
    "def train(model, train_loader, optimizer, epoch):\n",
    "    model.train()\n",
    "    # train_loss_averager = make_averager()  # mantain a running average of the loss\n",
    "\n",
    "    # TRAIN\n",
    "    tqdm_iterator = tqdm(\n",
    "        enumerate(train_loader),\n",
    "        total=len(train_loader),\n",
    "        desc=\"\",\n",
    "        leave=True,\n",
    "    )\n",
    "\n",
    "    len_tr_dl_ds = len(train_loader.dataset)\n",
    "\n",
    "    for batch_idx, (data, target) in tqdm_iterator:\n",
    "        data, target = data.to(device, non_blocking=True), target.to(\n",
    "            device, non_blocking=True\n",
    "        )\n",
    "        output = model(data)\n",
    "        loss = F.cross_entropy(output, target)\n",
    "        model.zero_grad(set_to_none=True)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad(set_to_none=True)\n",
    "\n",
    "        # train_loss_averager(loss.item())\n",
    "        tqdm_iterator.set_description(\n",
    "            f\"Train Epoch: {epoch} [ {batch_idx * len(data)}/{len_tr_dl_ds} \\tLoss: {loss.item():.6f}]\"\n",
    "        )\n",
    "        tqdm_iterator.refresh()  # to show immediately the update\n",
    "    tqdm_iterator.close()\n",
    "\n",
    "    if np.isnan(loss.item()):\n",
    "        print(\"Loss is nan\")\n",
    "        raise Exception(\"Loss is nan\")\n",
    "        exit()\n",
    "\n",
    "\n",
    "# testing step\n",
    "def test(model, test_loader):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "\n",
    "    tqdm_iterator = tqdm(\n",
    "        enumerate(test_loader),\n",
    "        total=len(test_loader),\n",
    "        desc=\"\",\n",
    "        leave=True,\n",
    "    )\n",
    "\n",
    "    len_ts_dl_ds = len(test_loader.dataset)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (data, target) in tqdm_iterator:\n",
    "            data, target = data.to(device, non_blocking=True), target.to(\n",
    "                device, non_blocking=True\n",
    "            )\n",
    "            output = model(data)\n",
    "            test_loss += F.cross_entropy(output, target).item()  # sum up batch loss\n",
    "            # get the index of the max probability\n",
    "            pred = output.max(1, keepdim=True)[1]\n",
    "            correct += pred.eq(target.view_as(pred)).cpu().sum().item()\n",
    "            tqdm_iterator.set_description(\n",
    "                f\"Test Epoch: {epoch} [{batch_idx * len(data)}/{len_ts_dl_ds} \\tLoss: {test_loss:.6f}, Accuracy: {correct}/{len_ts_dl_ds} ({100.0 * correct / len_ts_dl_ds}%)\"\n",
    "            )\n",
    "    tqdm_iterator.refresh()  # to show immediately the update\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    print(f\"Validation Average loss: {test_loss:.6f}\")\n",
    "\n",
    "    tqdm_iterator.close()\n",
    "\n",
    "    # show an histogram of the weights of the model\n",
    "    \"\"\"start = -1\n",
    "    stop = 1\n",
    "    bins = 30\n",
    "    for param in model.parameters():\n",
    "        if param.requires_grad:\n",
    "            \n",
    "            hist = torch.histc(param.data, bins = bins, min = start, max = stop)\n",
    "            x = np.arange(start, stop, (stop-start)/bins)\n",
    "            plt.bar(x, hist.cpu(), align='center')\n",
    "            plt.ylabel('Frequency')\n",
    "            plt.show() \"\"\"\n",
    "\n",
    "    return correct / len(test_loader.dataset)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    learning_rate = 0.1\n",
    "    optimizer = optim.SGD(model_intrinsic.parameters(), lr=learning_rate)\n",
    "    # download and load MNIST Dataset\n",
    "    train_dataloader = DataLoader(\n",
    "        train_dataset,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        shuffle=True,\n",
    "        num_workers=0,\n",
    "        pin_memory=True,\n",
    "    )  # persistent_workers=True)\n",
    "    test_dataloader = DataLoader(\n",
    "        test_dataset,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        shuffle=True,\n",
    "        num_workers=0,\n",
    "        pin_memory=True,\n",
    "    )  # persistent_workers=True)\n",
    "    # train the model\n",
    "    best_acc, best_epoch = 0, 0\n",
    "    for epoch in range(1, 101):\n",
    "        train(model_intrinsic, train_dataloader, optimizer, epoch)\n",
    "        accuracy = test(model_intrinsic, test_dataloader)\n",
    "        print(\"Validation Accuracy: {}\".format(accuracy))\n",
    "        # save information to file\n",
    "        \"\"\" with open('results.txt', 'a') as f:\n",
    "            f.write(f\"\\nEpoch: {epoch}\")\n",
    "            f.write(f\"\\nValidation Accuracy: {accuracy}\")\n",
    "        f.close() \"\"\"\n",
    "        if accuracy > best_acc:\n",
    "            best_acc = accuracy\n",
    "            best_epoch = epoch\n",
    "            if best_acc >= 0.90:\n",
    "                torch.save(\n",
    "                    model_intrinsic.state_dict(), f\"lenet_mnist_{intrinsic_dim}.pt\"\n",
    "                )\n",
    "                # torch.save(model_intrinsic.state_dict(), f\"model_best_h{hidden_dim}_id{intrinsic_dim}_lay{num_layers}.pt\")\n",
    "                \"\"\" j = None\n",
    "                with open('results.json', 'r') as f:\n",
    "                    j = json.load(f)\n",
    "                f.close()\n",
    "                with open('results.json', 'w') as f:\n",
    "                    j[f\"fcmodel_h{hidden_dim}_id{intrinsic_dim}_lay{num_layers}\"] = {\"number_parameter\": num_params, \"hidden_dimension\": hidden_dim, \"number_layers\": num_layers, \"intrinsic_dimension\": intrinsic_dim, \"epoch\": epoch, \"validation_accuracy\": accuracy}\n",
    "                    json.dump(j, f, indent=4, separators=(',', ': ')) \n",
    "                break \"\"\"\n",
    "\n",
    "    \"\"\" j = None\n",
    "    with open('results_lenet.json', 'r') as f:\n",
    "        j = json.load(f)\n",
    "    f.close()\n",
    "    with open('results_lenet.json', 'w') as f:\n",
    "        j[f\"lenet_model_id{intrinsic_dim}_lr{learning_rate}\"] = {\"number_parameter\": num_params, \"intrinsic_dimension\": intrinsic_dim, \"epoch\": epoch, \n",
    "        \"validation_accuracy\": accuracy, \"learning_rate\": learning_rate, \"best_epoch\": best_epoch, \"best_accuracy\": best_acc}\n",
    "        json.dump(j, f, indent=4, separators=(',', ': '))\n",
    "    f.close() \"\"\"\n",
    "\n",
    "    \"\"\" j = None\n",
    "    with open('results_lenet.json', 'r') as f:\n",
    "        j = json.load(f)\n",
    "    f.close()\n",
    "    with open('results_lenet.json', 'w') as f:\n",
    "        j[f\"fcmodel_h{hidden_dim}_id{intrinsic_dim}_lay{num_layers}_lr{learning_rate}\"] = {\"number_parameter\": num_params, \n",
    "        \"hidden_dimension\": hidden_dim, \"number_layers\": num_layers, \"intrinsic_dimension\": intrinsic_dim, \"epoch\": epoch, \n",
    "        \"validation_accuracy\": accuracy, \"learning_rate\": learning_rate, \"best_epoch\": best_epoch, \"best_accuracy\": best_acc}\n",
    "        json.dump(j, f, indent=4, separators=(',', ': '))\n",
    "    f.close() \"\"\"\n",
    "\"\"\"     j = None\n",
    "    with open('results.json', 'r') as f:\n",
    "        j = json.load(f)\n",
    "    f.close()\n",
    "    with open('results.json', 'w') as f:\n",
    "        j[f\"fcmodel_h{hidden_dim}_id{intrinsic_dim}_lay{num_layers}\"] = {\"number_parameter\": num_params, \"hidden_dimension\": hidden_dim, \"number_layers\": num_layers, \"intrinsic_dimension\": intrinsic_dim, \"epoch\": epoch, \"validation_accuracy\": accuracy}\n",
    "        json.dump(j, f, indent=4, separators=(',', ': ')) \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "error_y": {
          "array": [
           1,
           2,
           3,
           4,
           5
          ],
          "type": "data",
          "visible": true
         },
         "marker": {
          "color": [
           1,
           2,
           3,
           4,
           5
          ],
          "showscale": true,
          "size": 30
         },
         "mode": "markers",
         "name": "layer width: 50",
         "type": "scatter",
         "x": [
          1,
          3.2,
          5.4,
          7.6,
          9.8
         ],
         "y": [
          1,
          3.2,
          5.4,
          7.6,
          9.8
         ]
        },
        {
         "error_y": {
          "array": [
           1,
           2,
           3,
           4,
           5
          ],
          "type": "data",
          "visible": true
         },
         "marker": {
          "color": [
           1,
           2,
           3,
           4,
           5
          ],
          "showscale": true,
          "size": 55
         },
         "mode": "markers",
         "name": "layer width: 100",
         "type": "scatter",
         "x": [
          1,
          3.2,
          5.4,
          7.6,
          9.8
         ],
         "y": [
          1,
          3.2,
          5.4,
          7.6,
          9.8
         ]
        },
        {
         "error_y": {
          "array": [
           1,
           2,
           3,
           4,
           5
          ],
          "type": "data",
          "visible": true
         },
         "marker": {
          "color": [
           1,
           2,
           3,
           4,
           5
          ],
          "showscale": true,
          "size": 70
         },
         "mode": "markers",
         "name": "layer width: 200",
         "type": "scatter",
         "x": [
          1,
          3.2,
          5.4,
          7.6,
          9.8
         ],
         "y": [
          1,
          3.2,
          5.4,
          7.6,
          9.8
         ]
        },
        {
         "error_y": {
          "array": [
           1,
           2,
           3,
           4,
           5
          ],
          "type": "data",
          "visible": true
         },
         "marker": {
          "color": [
           1,
           2,
           3,
           4,
           5
          ],
          "showscale": true,
          "size": 90
         },
         "mode": "markers",
         "name": "layer width: 400",
         "type": "scatter",
         "x": [
          1,
          3.2,
          5.4,
          7.6,
          9.8
         ],
         "y": [
          1,
          3.2,
          5.4,
          7.6,
          9.8
         ]
        }
       ],
       "layout": {
        "legend": {
         "x": 0.01,
         "xanchor": "left",
         "y": 0.99,
         "yanchor": "top"
        },
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = go.Figure()\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=[1, 3.2, 5.4, 7.6, 9.8],\n",
    "        y=[1, 3.2, 5.4, 7.6, 9.8],\n",
    "        mode=\"markers\",\n",
    "        marker=dict(color=[1, 2, 3, 4, 5], size=30, showscale=True),\n",
    "        error_y=dict(\n",
    "            type=\"data\",  # value of error bar given in data coordinates\n",
    "            array=[1, 2, 3, 4, 5],\n",
    "            visible=True,\n",
    "        ),\n",
    "        name=\"layer width: 50\",\n",
    "    )\n",
    ")\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=[1, 3.2, 5.4, 7.6, 9.8],\n",
    "        y=[1, 3.2, 5.4, 7.6, 9.8],\n",
    "        mode=\"markers\",\n",
    "        marker=dict(color=[1, 2, 3, 4, 5], size=55, showscale=True),\n",
    "        error_y=dict(\n",
    "            type=\"data\",  # value of error bar given in data coordinates\n",
    "            array=[1, 2, 3, 4, 5],\n",
    "            visible=True,\n",
    "        ),\n",
    "        name=\"layer width: 100\",\n",
    "    )\n",
    ")\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=[1, 3.2, 5.4, 7.6, 9.8],\n",
    "        y=[1, 3.2, 5.4, 7.6, 9.8],\n",
    "        mode=\"markers\",\n",
    "        marker=dict(color=[1, 2, 3, 4, 5], size=70, showscale=True),\n",
    "        error_y=dict(\n",
    "            type=\"data\",  # value of error bar given in data coordinates\n",
    "            array=[1, 2, 3, 4, 5],\n",
    "            visible=True,\n",
    "        ),\n",
    "        name=\"layer width: 200\",\n",
    "    )\n",
    ")\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=[1, 3.2, 5.4, 7.6, 9.8],\n",
    "        y=[1, 3.2, 5.4, 7.6, 9.8],\n",
    "        mode=\"markers\",\n",
    "        marker=dict(color=[1, 2, 3, 4, 5], size=90, showscale=True),\n",
    "        error_y=dict(\n",
    "            type=\"data\",  # value of error bar given in data coordinates\n",
    "            array=[1, 2, 3, 4, 5],\n",
    "            visible=True,\n",
    "        ),\n",
    "        name=\"layer width: 400\",\n",
    "    )\n",
    ")\n",
    "\n",
    "fig.update_layout(legend=dict(yanchor=\"top\", y=0.99, xanchor=\"left\", x=0.01))\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(indices=tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "                       [0, 0, 0, 1, 1, 1, 2, 2, 2, 0, 0, 0, 1, 1, 1, 2, 2, 2],\n",
      "                       [0, 1, 2, 0, 1, 2, 0, 1, 2, 0, 1, 2, 0, 1, 2, 0, 1, 2]]),\n",
      "       values=tensor([ 0.9655,  0.0582, -0.4156,  0.9375,  0.8889,  0.8146,\n",
      "                       1.3595,  0.6110,  0.8078, -1.6604,  0.1609,  0.1043,\n",
      "                      -0.5520,  0.2414,  0.0949, -0.1879, -0.5083, -0.8864]),\n",
      "       size=(2, 3, 3), nnz=18, layout=torch.sparse_coo)\n",
      "tensor([[-1.3109],\n",
      "        [ 0.8592],\n",
      "        [-0.2531]], requires_grad=True)\n",
      "tensor([[[-1.1105],\n",
      "         [-0.6714],\n",
      "         [-1.4617]],\n",
      "\n",
      "        [[ 2.2885],\n",
      "         [ 0.9070],\n",
      "         [ 0.0339]]], grad_fn=<BmmBackward0>)\n",
      "False\n",
      "tensor([[0.8622],\n",
      "        [1.4521],\n",
      "        [0.5196]])\n"
     ]
    }
   ],
   "source": [
    "a = (\n",
    "    torch.tensor(\n",
    "        [\n",
    "            [\n",
    "                [0.9655, 0.0582, -0.4156],\n",
    "                [0.9375, 0.8889, 0.8146],\n",
    "                [1.3595, 0.6110, 0.8078],\n",
    "            ],\n",
    "            [\n",
    "                [-1.6604, 0.1609, 0.1043],\n",
    "                [-0.5520, 0.2414, 0.0949],\n",
    "                [-0.1879, -0.5083, -0.8864],\n",
    "            ],\n",
    "        ]\n",
    "    )\n",
    "    .to_sparse()\n",
    "    .requires_grad_(False)\n",
    ")\n",
    "print(a)\n",
    "\n",
    "b = torch.tensor([[-1.3109], [0.8592], [-0.2531]], requires_grad=True)\n",
    "print(b)\n",
    "\n",
    "y = torch.bmm(a, b.broadcast_to((a.shape[0], b.shape[0], b.shape[-1])))\n",
    "print(y)\n",
    "print(y.is_sparse)\n",
    "\n",
    "y.sum().backward()\n",
    "print(b.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 0.9655,  0.0582, -0.4156],\n",
      "         [ 0.9375,  0.8889,  0.8146],\n",
      "         [ 1.3595,  0.6110,  0.8078]],\n",
      "\n",
      "        [[-1.6604,  0.1609,  0.1043],\n",
      "         [-0.5520,  0.2414,  0.0949],\n",
      "         [-0.1879, -0.5083, -0.8864]]])\n",
      "tensor([[-1.3109],\n",
      "        [ 0.8592],\n",
      "        [-0.2531]], requires_grad=True)\n",
      "tensor([[[-1.1105],\n",
      "         [-0.6714],\n",
      "         [-1.4617]],\n",
      "\n",
      "        [[ 2.2885],\n",
      "         [ 0.9070],\n",
      "         [ 0.0339]]], grad_fn=<UnsafeViewBackward0>)\n",
      "tensor([[0.8622],\n",
      "        [1.4521],\n",
      "        [0.5196]])\n"
     ]
    }
   ],
   "source": [
    "a = torch.tensor(\n",
    "    [\n",
    "        [[0.9655, 0.0582, -0.4156], [0.9375, 0.8889, 0.8146], [1.3595, 0.6110, 0.8078]],\n",
    "        [\n",
    "            [-1.6604, 0.1609, 0.1043],\n",
    "            [-0.5520, 0.2414, 0.0949],\n",
    "            [-0.1879, -0.5083, -0.8864],\n",
    "        ],\n",
    "    ]\n",
    ").requires_grad_(False)\n",
    "print(a)\n",
    "\n",
    "b = torch.tensor([[-1.3109], [0.8592], [-0.2531]], requires_grad=True)\n",
    "print(b)\n",
    "\n",
    "y = torch.matmul(a, b)\n",
    "print(y)\n",
    "\n",
    "y.sum().backward()\n",
    "print(b.grad)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e13549091eeb6d212316983f0d9bb375e4ef3e549472c705cc2bde65fe2521f7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
