{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU is available\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision.models as models\n",
    "import numpy as np\n",
    "from torchvision import models, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.datasets import MNIST, CIFAR10\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    print(\"GPU is available\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"GPU is not available\")\n",
    "\n",
    "# add reproducibility stuff\n",
    "torch.manual_seed(42)\n",
    "torch.cuda.manual_seed_all(42)\n",
    "np.random.seed(42)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fastfood_vars(DD, device=0):\n",
    "    \"\"\"\n",
    "    Returns parameters for fast food transform\n",
    "    :param DD: desired dimension\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    ll = int(np.ceil(np.log(DD) / np.log(2)))\n",
    "    LL = 2**ll\n",
    "\n",
    "    # Binary scaling matrix where $B_{i,i} \\in \\{\\pm 1 \\}$ drawn iid\n",
    "    BB = torch.FloatTensor(LL).uniform_(0, 2).type(torch.LongTensor)\n",
    "    BB = (BB * 2 - 1).type(torch.FloatTensor).to(device)\n",
    "    BB.requires_grad = False\n",
    "\n",
    "    # Random permutation matrix\n",
    "    Pi = torch.LongTensor(np.random.permutation(LL)).to(device)\n",
    "    Pi.requires_grad = False\n",
    "\n",
    "    # Gaussian scaling matrix, whose elements $G_{i,i} \\sim \\mathcal{N}(0, 1)$\n",
    "    GG = (\n",
    "        torch.FloatTensor(\n",
    "            LL,\n",
    "        )\n",
    "        .normal_()\n",
    "        .to(device)\n",
    "    )\n",
    "    GG.requires_grad = False\n",
    "\n",
    "    divisor = torch.sqrt(LL * torch.sum(torch.pow(GG, 2)))\n",
    "\n",
    "    return [BB, Pi, GG, divisor, LL]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fast_walsh_hadamard_torched(x, axis=0, normalize=False):\n",
    "    \"\"\"\n",
    "    Performs fast Walsh Hadamard transform\n",
    "    :param x:\n",
    "    :param axis:\n",
    "    :param normalize:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    orig_shape = x.size()\n",
    "    assert axis >= 0 and axis < len(\n",
    "        orig_shape\n",
    "    ), \"For a vector of shape %s, axis must be in [0, %d] but it is %d\" % (\n",
    "        orig_shape,\n",
    "        len(orig_shape) - 1,\n",
    "        axis,\n",
    "    )\n",
    "    h_dim = orig_shape[axis]\n",
    "    h_dim_exp = int(round(np.log(h_dim) / np.log(2)))\n",
    "    assert h_dim == 2**h_dim_exp, (\n",
    "        \"hadamard can only be computed over axis with size that is a power of two, but\"\n",
    "        \" chosen axis %d has size %d\" % (axis, h_dim)\n",
    "    )\n",
    "\n",
    "    working_shape_pre = [int(np.prod(orig_shape[:axis]))]  # prod of empty array is 1 :)\n",
    "    working_shape_post = [\n",
    "        int(np.prod(orig_shape[axis + 1 :]))\n",
    "    ]  # prod of empty array is 1 :)\n",
    "    working_shape_mid = [2] * h_dim_exp\n",
    "    working_shape = working_shape_pre + working_shape_mid + working_shape_post\n",
    "\n",
    "    ret = x.view(working_shape)\n",
    "\n",
    "    for ii in range(h_dim_exp):\n",
    "        dim = ii + 1\n",
    "        arrs = torch.chunk(ret, 2, dim=dim)\n",
    "        assert len(arrs) == 2\n",
    "        ret = torch.cat((arrs[0] + arrs[1], arrs[0] - arrs[1]), axis=dim)\n",
    "\n",
    "    if normalize:\n",
    "        ret = ret / torch.sqrt(float(h_dim))\n",
    "\n",
    "    ret = ret.view(orig_shape)\n",
    "\n",
    "    return ret\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fastfood_torched(x, DD, param_list=None, device=0):\n",
    "    \"\"\"\n",
    "    Fastfood transform\n",
    "    :param x: array of dd dimension\n",
    "    :param DD: desired dimension\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    dd = x.size(0)\n",
    "\n",
    "    if not param_list:\n",
    "\n",
    "        BB, Pi, GG, divisor, LL = fastfood_vars(DD, device=device)\n",
    "\n",
    "    else:\n",
    "\n",
    "        BB, Pi, GG, divisor, LL = param_list\n",
    "\n",
    "    # Padd x if needed\n",
    "    dd_pad = F.pad(x, pad=(0, LL - dd), value=0, mode=\"constant\")\n",
    "\n",
    "    # From left to right HGPiH(BX), where H is Walsh-Hadamard matrix\n",
    "    mul_1 = torch.mul(BB, dd_pad)\n",
    "    # HGPi(HBX)\n",
    "    mul_2 = fast_walsh_hadamard_torched(mul_1, 0, normalize=False)\n",
    "\n",
    "    # HG(PiHBX)\n",
    "    mul_3 = mul_2[Pi]\n",
    "\n",
    "    # H(GPiHBX)\n",
    "    mul_4 = torch.mul(mul_3, GG)\n",
    "\n",
    "    # (HGPiHBX)\n",
    "    mul_5 = fast_walsh_hadamard_torched(mul_4, 0, normalize=False)\n",
    "\n",
    "    ret = torch.div(mul_5[:DD], divisor * np.sqrt(float(DD) / LL))\n",
    "\n",
    "    return ret\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FastfoodWrapper(nn.Module):\n",
    "    def __init__(self, module, intrinsic_dimension, device):\n",
    "        \"\"\"\n",
    "        Wrapper to estimate the intrinsic dimensionality of the\n",
    "        objective landscape for a specific task given a specific model using FastFood transform\n",
    "        :param module: pytorch nn.Module\n",
    "        :param intrinsic_dimension: dimensionality within which we search for solution\n",
    "        :param device: cuda device id\n",
    "        \"\"\"\n",
    "        super(FastfoodWrapper, self).__init__()\n",
    "\n",
    "        # Hide this from inspection by get_parameters()\n",
    "        self.m = [module]\n",
    "\n",
    "        self.name_base_localname = []\n",
    "\n",
    "        # Stores the initial value: \\theta_{0}^{D}\n",
    "        self.initial_value = dict()\n",
    "\n",
    "        # Fastfood parameters\n",
    "        self.fastfood_params = {}\n",
    "\n",
    "        # Parameter vector that is updated\n",
    "        # Initialised with zeros as per text: \\theta^{d}\n",
    "        V = nn.Parameter(torch.zeros((intrinsic_dimension)).to(device))\n",
    "        self.register_parameter(\"V\", V)\n",
    "        v_size = (intrinsic_dimension,)\n",
    "\n",
    "        # Iterate over layers in the module\n",
    "        for name, param in module.named_parameters():\n",
    "            # If param requires grad update\n",
    "            if param.requires_grad:\n",
    "\n",
    "                # Saves the initial values of the initialised parameters from param.data and sets them to no grad.\n",
    "                # (initial values are the 'origin' of the search)\n",
    "                self.initial_value[name] = v0 = (\n",
    "                    param.clone().detach().requires_grad_(False).to(device)\n",
    "                )\n",
    "\n",
    "                # Generate fastfood parameters\n",
    "                DD = np.prod(v0.size())\n",
    "                self.fastfood_params[name] = fastfood_vars(DD, device)\n",
    "\n",
    "                base, localname = module, name\n",
    "                while \".\" in localname:\n",
    "                    prefix, localname = localname.split(\".\", 1)\n",
    "                    base = base.__getattr__(prefix)\n",
    "                self.name_base_localname.append((name, base, localname))\n",
    "\n",
    "        for name, base, localname in self.name_base_localname:\n",
    "            delattr(base, localname)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Iterate over layers\n",
    "        for name, base, localname in self.name_base_localname:\n",
    "\n",
    "            init_shape = self.initial_value[name].size()\n",
    "            DD = np.prod(init_shape)\n",
    "\n",
    "            # Fastfood transform te replace dence P\n",
    "            ray = fastfood_torched(self.V, DD, self.fastfood_params[name]).view(\n",
    "                init_shape\n",
    "            )\n",
    "\n",
    "            param = self.initial_value[name] + ray\n",
    "\n",
    "            setattr(base, localname, param)\n",
    "\n",
    "        # Pass through the model, by getting hte module from a list self.m\n",
    "        module = self.m[0]\n",
    "        x = module(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DenseWrap(nn.Module):\n",
    "    def __init__(self, module, intrinsic_dimension, device):\n",
    "        \"\"\"\n",
    "        Wrapper to estimate the intrinsic dimensionality of the\n",
    "        objective landscape for a specific task given a specific model\n",
    "        :param module: pytorch nn.Module\n",
    "        :param intrinsic_dimension: dimensionality within which we search for solution\n",
    "        :param device: cuda device id\n",
    "        \"\"\"\n",
    "        super(DenseWrap, self).__init__()\n",
    "\n",
    "        # Hide this from inspection by get_parameters()\n",
    "        self.m = [module]\n",
    "\n",
    "        self.name_base_localname = []\n",
    "\n",
    "        # Stores the initial value: \\theta_{0}^{D}\n",
    "        self.initial_value = dict()\n",
    "\n",
    "        # Stores the randomly generated projection matrix P\n",
    "        self.random_matrix = dict()\n",
    "\n",
    "        # Parameter vector that is updated, initialised with zeros as per text: \\theta^{d}\n",
    "        V = nn.Parameter(torch.zeros((intrinsic_dimension, 1)).to(device))\n",
    "        self.register_parameter(\"V\", V)\n",
    "        v_size = (intrinsic_dimension,)\n",
    "\n",
    "        # Iterates over layers in the Neural Network\n",
    "        for name, param in module.named_parameters():\n",
    "            # If the parameter requires gradient update\n",
    "            if param.requires_grad:\n",
    "\n",
    "                # Saves the initial values of the initialised parameters from param.data and sets them to no grad.\n",
    "                # (initial values are the 'origin' of the search)\n",
    "                self.initial_value[name] = v0 = (\n",
    "                    param.clone().detach().requires_grad_(False).to(device)\n",
    "                )\n",
    "\n",
    "                # If v0.size() is [4, 3], then below operation makes it [4, 3, v_size]\n",
    "                matrix_size = v0.size() + v_size\n",
    "\n",
    "                # Generates random projection matrices P, sets them to no grad\n",
    "                self.random_matrix[name] = (\n",
    "                    torch.randn(matrix_size, requires_grad=False).to(device)\n",
    "                    / intrinsic_dimension**0.5\n",
    "                )\n",
    "\n",
    "                # NOTE!: lines below are not clear!\n",
    "                base, localname = module, name\n",
    "                while \".\" in localname:\n",
    "                    prefix, localname = localname.split(\".\", 1)\n",
    "                    base = base.__getattr__(prefix)\n",
    "                self.name_base_localname.append((name, base, localname))\n",
    "\n",
    "        for name, base, localname in self.name_base_localname:\n",
    "            delattr(base, localname)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Iterate over the layers\n",
    "        for name, base, localname in self.name_base_localname:\n",
    "\n",
    "            # Product between matrix P and \\theta^{d}\n",
    "            ray = torch.matmul(self.random_matrix[name], self.V)\n",
    "\n",
    "            # Add the \\theta_{0}^{D} to P \\dot \\theta^{d}\n",
    "            param = self.initial_value[name] + torch.squeeze(ray, -1)\n",
    "\n",
    "            setattr(base, localname, param)\n",
    "\n",
    "        # Pass through the model, by getting the module from a list self.m\n",
    "        module = self.m[0]\n",
    "        x = module(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'class Classifier(nn.Module):\\n    def __init__(self, input_dim, n_classes):\\n        super(Classifier, self).__init__()\\n        self.fc = nn.Linear(input_dim, n_classes)\\n        self.maxpool = nn.AdaptiveMaxPool2d(1)\\n\\n    def forward(self, x):\\n        x = self.maxpool(x)\\n        x = x.reshape(x.size(0), -1)\\n        x = self.fc(x)\\n        return x\\n\\n\\ndef get_resnet(encoder_name, num_classes, pretrained=False):\\n    assert encoder_name in [\\n        \"resnet18\",\\n        \"resnet50\",\\n    ], \"{} is a wrong encoder name!\".format(encoder_name)\\n    if encoder_name == \"resnet18\":\\n        model = models.resnet18(pretrained=pretrained)\\n        latent_dim = 512\\n    else:\\n        model = models.resnet50(pretrained=pretrained)\\n        latent_dim = 2048\\n    children = list(model.children())[:-2] + [Classifier(latent_dim, num_classes)]\\n    model = torch.nn.Sequential(*children)\\n    return model\\n\\n\\n# Get model and wrap it in fastfood\\nmodel = get_resnet(\"resnet18\", num_classes=YOUR_NUMBER_OF_CLASSES).cuda()\\nmodel = FastfoodWrapper(model, intrinsic_dimension=100, device=device)'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# implementig the code from the paper https://arxiv.org/abs/1804.08838 in pytorch\n",
    "\"\"\"class Classifier(nn.Module):\n",
    "    def __init__(self, input_dim, n_classes):\n",
    "        super(Classifier, self).__init__()\n",
    "        self.fc = nn.Linear(input_dim, n_classes)\n",
    "        self.maxpool = nn.AdaptiveMaxPool2d(1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.maxpool(x)\n",
    "        x = x.reshape(x.size(0), -1)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "def get_resnet(encoder_name, num_classes, pretrained=False):\n",
    "    assert encoder_name in [\n",
    "        \"resnet18\",\n",
    "        \"resnet50\",\n",
    "    ], \"{} is a wrong encoder name!\".format(encoder_name)\n",
    "    if encoder_name == \"resnet18\":\n",
    "        model = models.resnet18(pretrained=pretrained)\n",
    "        latent_dim = 512\n",
    "    else:\n",
    "        model = models.resnet50(pretrained=pretrained)\n",
    "        latent_dim = 2048\n",
    "    children = list(model.children())[:-2] + [Classifier(latent_dim, num_classes)]\n",
    "    model = torch.nn.Sequential(*children)\n",
    "    return model\n",
    "\n",
    "\n",
    "# Get model and wrap it in fastfood\n",
    "model = get_resnet(\"resnet18\", num_classes=YOUR_NUMBER_OF_CLASSES).cuda()\n",
    "model = FastfoodWrapper(model, intrinsic_dimension=100, device=device)\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 128\n",
    "DATASET_NAME = \"MNIST\"\n",
    "\n",
    "img_transform = transforms.Compose(\n",
    "    [transforms.ToTensor()]\n",
    ")\n",
    "\n",
    "train_dataset = None\n",
    "test_dataset = None\n",
    "if DATASET_NAME == \"MNIST\":\n",
    "    train_dataset = MNIST(\n",
    "        root=\"./data/MNIST\", download=True, train=True, transform=img_transform\n",
    "    )\n",
    "    test_dataset = MNIST(\n",
    "    root=\"./data/MNIST\", download=True, train=False, transform=img_transform\n",
    "    )\n",
    "elif DATASET_NAME == \"CIFAR10\":\n",
    "    train_dataset = CIFAR10(\n",
    "    root=\"./data/CIFAR10\", download=True, train=True, transform=img_transform\n",
    "    )\n",
    "    test_dataset = CIFAR10(\n",
    "    root=\"./data/CIFAR10\", download=True, train=False, transform=img_transform\n",
    "    )\n",
    "else:\n",
    "    raise Exception(\"Name of dataset not in: [MNIST, CIFAR10]\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "coloraxis": "coloraxis",
         "hovertemplate": "x: %{x}<br>y: %{y}<br>color: %{z}<extra></extra>",
         "name": "0",
         "type": "heatmap",
         "xaxis": "x",
         "yaxis": "y",
         "z": [
          [
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0
          ],
          [
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0
          ],
          [
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0
          ],
          [
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0
          ],
          [
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0
          ],
          [
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           3,
           18,
           18,
           18,
           126,
           136,
           175,
           26,
           166,
           255,
           247,
           127,
           0,
           0,
           0,
           0
          ],
          [
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           30,
           36,
           94,
           154,
           170,
           253,
           253,
           253,
           253,
           253,
           225,
           172,
           253,
           242,
           195,
           64,
           0,
           0,
           0,
           0
          ],
          [
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           49,
           238,
           253,
           253,
           253,
           253,
           253,
           253,
           253,
           253,
           251,
           93,
           82,
           82,
           56,
           39,
           0,
           0,
           0,
           0,
           0
          ],
          [
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           18,
           219,
           253,
           253,
           253,
           253,
           253,
           198,
           182,
           247,
           241,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0
          ],
          [
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           80,
           156,
           107,
           253,
           253,
           205,
           11,
           0,
           43,
           154,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0
          ],
          [
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           14,
           1,
           154,
           253,
           90,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0
          ],
          [
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           139,
           253,
           190,
           2,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0
          ],
          [
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           11,
           190,
           253,
           70,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0
          ],
          [
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           35,
           241,
           225,
           160,
           108,
           1,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0
          ],
          [
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           81,
           240,
           253,
           253,
           119,
           25,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0
          ],
          [
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           45,
           186,
           253,
           253,
           150,
           27,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0
          ],
          [
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           16,
           93,
           252,
           253,
           187,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0
          ],
          [
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           249,
           253,
           249,
           64,
           0,
           0,
           0,
           0,
           0,
           0,
           0
          ],
          [
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           46,
           130,
           183,
           253,
           253,
           207,
           2,
           0,
           0,
           0,
           0,
           0,
           0,
           0
          ],
          [
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           39,
           148,
           229,
           253,
           253,
           253,
           250,
           182,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0
          ],
          [
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           24,
           114,
           221,
           253,
           253,
           253,
           253,
           201,
           78,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0
          ],
          [
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           23,
           66,
           213,
           253,
           253,
           253,
           253,
           198,
           81,
           2,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0
          ],
          [
           0,
           0,
           0,
           0,
           0,
           0,
           18,
           171,
           219,
           253,
           253,
           253,
           253,
           195,
           80,
           9,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0
          ],
          [
           0,
           0,
           0,
           0,
           55,
           172,
           226,
           253,
           253,
           253,
           253,
           244,
           133,
           11,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0
          ],
          [
           0,
           0,
           0,
           0,
           136,
           253,
           253,
           253,
           212,
           135,
           132,
           16,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0
          ],
          [
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0
          ],
          [
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0
          ],
          [
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0
          ]
         ]
        }
       ],
       "layout": {
        "coloraxis": {
         "colorscale": [
          [
           0,
           "#0d0887"
          ],
          [
           0.1111111111111111,
           "#46039f"
          ],
          [
           0.2222222222222222,
           "#7201a8"
          ],
          [
           0.3333333333333333,
           "#9c179e"
          ],
          [
           0.4444444444444444,
           "#bd3786"
          ],
          [
           0.5555555555555556,
           "#d8576b"
          ],
          [
           0.6666666666666666,
           "#ed7953"
          ],
          [
           0.7777777777777778,
           "#fb9f3a"
          ],
          [
           0.8888888888888888,
           "#fdca26"
          ],
          [
           1,
           "#f0f921"
          ]
         ]
        },
        "margin": {
         "t": 60
        },
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "xaxis": {
         "anchor": "y",
         "constrain": "domain",
         "domain": [
          0,
          1
         ],
         "scaleanchor": "y"
        },
        "yaxis": {
         "anchor": "x",
         "autorange": "reversed",
         "constrain": "domain",
         "domain": [
          0,
          1
         ]
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if DATASET_NAME == \"MNIST\":\n",
    "    channel_in = 1\n",
    "    input_height = 28\n",
    "    input_width = 28\n",
    "    input_dim = input_height*input_width*channel_in\n",
    "    output_dim = 10\n",
    "    idx = 0 # @param {type:\"slider\", min:0, max:59999, step:1}\n",
    "else:\n",
    "    channel_in = 3\n",
    "    input_height = 32\n",
    "    input_width = 32\n",
    "    input_dim = input_height*input_width*channel_in\n",
    "    output_dim = 10\n",
    "    idx = 0 # @param {type:\"slider\", min:0, max:49999, step:1}\n",
    "\n",
    "px.imshow(train_dataset.data[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class for a Fully Connected Network\n",
    "class FullyConnectedNetwork(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim, num_layers):\n",
    "        super(FullyConnectedNetwork, self).__init__()\n",
    "        self.num_layers = num_layers\n",
    "        self.fc_in = nn.Linear(input_dim, hidden_dim)\n",
    "        if num_layers > 0:\n",
    "            self.fcs = nn.ModuleList([nn.Linear(hidden_dim, hidden_dim) for _ in range(num_layers)])\n",
    "        self.fc_out = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.flatten(x, start_dim=1)\n",
    "        x = F.relu(self.fc_in(x))\n",
    "        if self.num_layers > 0:\n",
    "            for fc in self.fcs: \n",
    "                x = F.relu(fc(x))\n",
    "        x = self.fc_out(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class for Standard LeNet Network, reference http://vision.stanford.edu/cs598_spring07/papers/Lecun98.pdf with some modification to follow the same number of parameters as the main paper for the task does\n",
    "class LeNet(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super(LeNet, self).__init__()\n",
    "        # 6 kernels 5x5\n",
    "        self.conv1 = nn.Conv2d(input_dim, 6, 5, padding='valid',)\n",
    "        # max-pooling over 2x2\n",
    "        self.pool1 = nn.MaxPool2d(2, stride=2)\n",
    "        # 16 kernels 5x5\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5, padding='valid')\n",
    "        # max-pooling over 2x2\n",
    "        self.pool2 = nn.MaxPool2d(2, stride=2)\n",
    "        # 120 kernels 4x4 to match the dimensionality of the fully connected network\n",
    "        self.conv3 = nn.Conv2d(16, 120, 5,)\n",
    "        # 120 fully connected neurons, too many parameter in this case w.r.t. the paper\n",
    "        #self.fc1 = nn.Linear(16 * 5 * 5, 120,)\n",
    "        self.flat = nn.Flatten(start_dim=1)\n",
    "        # 84 fully connected neurons\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        # 10 fully connected neurons\n",
    "        self.fc3 = nn.Linear(84, output_dim,)\n",
    "\n",
    "    def forward(self, x):\n",
    "        #x = x.view(-1, 1, 28, 28)\n",
    "        print(x.shape)\n",
    "        x = self.conv1(x)\n",
    "        print(x.shape)\n",
    "        x = self.pool1(F.relu(x))\n",
    "        print(x.shape)\n",
    "        x = self.pool2(F.relu(self.conv2(x)))\n",
    "        print(x.shape)\n",
    "        x = F.relu(self.conv3(x))\n",
    "        x = self.flat(x)\n",
    "        #x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' class Untied_LeNet(nn.Module):\\n    def __init__(self, input_dim, output_dim):\\n        super(Untied_LeNet, self).__init__()\\n        # 6 kernels 5x5\\n        self.conv1 = LocallyConnected2d(input_dim, 6, (24,24), 5)\\n        # max-pooling over 2x2\\n        self.pool1 = nn.MaxPool2d(2, stride=2)\\n        # 16 kernels 5x5\\n        self.conv2 = LocallyConnected2d(6, 16, (8,8), 5)\\n        # max-pooling over 2x2\\n        self.pool2 = nn.MaxPool2d(2, stride=2)\\n        # 120 kernels 4x4 to match the dimensionality of the fully connected network\\n        self.conv3 = LocallyConnected2d(16, 120, (1,1), 4)\\n        # 120 fully connected neurons, too many parameter in this case w.r.t. the paper\\n        #self.fc1 = nn.Linear(16 * 5 * 5, 120,)\\n        self.flat = nn.Flatten(start_dim=1)\\n        # 84 fully connected neurons\\n        self.fc2 = nn.Linear(120, 84)\\n        # 10 fully connected neurons\\n        self.fc3 = nn.Linear(84, output_dim,)\\n\\n    def forward(self, x):\\n        #x = x.view(-1, 1, 28, 28)\\n        x = self.pool1(F.relu(self.conv1(x)))\\n        x = self.pool2(F.relu(self.conv2(x)))\\n        x = F.relu(self.conv3(x))\\n        x = self.flat(x)\\n        #x = F.relu(self.fc1(x))\\n        x = F.relu(self.fc2(x))\\n        x = self.fc3(x)\\n        return x '"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch.nn.modules.utils import _pair\n",
    "\n",
    "# from https://discuss.pytorch.org/t/locally-connected-layers/26979\n",
    "class LocallyConnected2d(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, output_size, kernel_size, stride=1, bias=True):\n",
    "        super(LocallyConnected2d, self).__init__()\n",
    "        output_size = _pair(output_size)\n",
    "        self.weight = nn.Parameter(\n",
    "            nn.init.kaiming_normal_(torch.randn(1, out_channels, in_channels, output_size[0], output_size[1], kernel_size**2), nonlinearity='relu')\n",
    "        )\n",
    "        if bias:\n",
    "            self.bias = nn.Parameter(nn.init.kaiming_normal_(\n",
    "                torch.randn(1, out_channels, output_size[0], output_size[1]), nonlinearity='relu')\n",
    "            )\n",
    "        else:\n",
    "            self.register_parameter('bias', None)\n",
    "        self.kernel_size = _pair(kernel_size)\n",
    "        self.stride = _pair(stride)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        _, c, h, w = x.size()\n",
    "        kh, kw = self.kernel_size\n",
    "        dh, dw = self.stride\n",
    "        x = x.unfold(2, kh, dh).unfold(3, kw, dw)\n",
    "        x = x.contiguous().view(*x.size()[:-2], -1)\n",
    "        # Sum in in_channel and kernel_size dims\n",
    "        out = (x.unsqueeze(1) * self.weight).sum([2, -1])\n",
    "        if self.bias is not None:\n",
    "            out += self.bias\n",
    "        return out\n",
    "\n",
    "# Class for Untied LeNet Network\n",
    "\"\"\" class Untied_LeNet(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super(Untied_LeNet, self).__init__()\n",
    "        # 6 kernels 5x5\n",
    "        self.conv1 = LocallyConnected2d(input_dim, 6, (24,24), 5)\n",
    "        # max-pooling over 2x2\n",
    "        self.pool1 = nn.MaxPool2d(2, stride=2)\n",
    "        # 16 kernels 5x5\n",
    "        self.conv2 = LocallyConnected2d(6, 16, (8,8), 5)\n",
    "        # max-pooling over 2x2\n",
    "        self.pool2 = nn.MaxPool2d(2, stride=2)\n",
    "        # 120 kernels 4x4 to match the dimensionality of the fully connected network\n",
    "        self.conv3 = LocallyConnected2d(16, 120, (1,1), 4)\n",
    "        # 120 fully connected neurons, too many parameter in this case w.r.t. the paper\n",
    "        #self.fc1 = nn.Linear(16 * 5 * 5, 120,)\n",
    "        self.flat = nn.Flatten(start_dim=1)\n",
    "        # 84 fully connected neurons\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        # 10 fully connected neurons\n",
    "        self.fc3 = nn.Linear(84, output_dim,)\n",
    "\n",
    "    def forward(self, x):\n",
    "        #x = x.view(-1, 1, 28, 28)\n",
    "        x = self.pool1(F.relu(self.conv1(x)))\n",
    "        x = self.pool2(F.relu(self.conv2(x)))\n",
    "        x = F.relu(self.conv3(x))\n",
    "        x = self.flat(x)\n",
    "        #x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class for general Untied LeNet Network\n",
    "class Untied_LeNet(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim, input_height, input_width):\n",
    "        super(Untied_LeNet, self).__init__()\n",
    "        # 6 kernels 5x5, output size 24x24 MNIST, output size 28x28 CIFAR10\n",
    "        self.kernel_size = 5\n",
    "        self.pool_kernel_size = 2\n",
    "        self.out_conv1 = (input_height-(self.kernel_size-1), input_width-(self.kernel_size-1))\n",
    "        self.conv1 = LocallyConnected2d(input_dim, 6, self.out_conv1, self.kernel_size)\n",
    "        # max-pooling over 2x2\n",
    "        self.pool1 = nn.MaxPool2d(self.pool_kernel_size, stride=2)\n",
    "        # 16 kernels 5x5 output size 8x8, output size 10x10 CIFAR10\n",
    "        self.out_conv2 = (int(self.out_conv1[0]/self.pool_kernel_size)-(self.kernel_size-1), int(self.out_conv1[1]/self.pool_kernel_size)-(self.kernel_size-1))\n",
    "        self.conv2 = LocallyConnected2d(6, 16, self.out_conv2, self.kernel_size)\n",
    "        # max-pooling over 2x2\n",
    "        self.pool2 = nn.MaxPool2d(self.pool_kernel_size, stride=2)\n",
    "        # 120 kernels 4x4 to match the dimensionality of the fully connected network and obtain an output size of 1x1 for MNIST and kernels 5x5 for CIFAR10\n",
    "        self.conv3 = LocallyConnected2d(16, 120, (1, 1), int(self.out_conv2[0]/self.pool_kernel_size))\n",
    "        # 120 fully connected neurons, too many parameter in this case w.r.t. the paper\n",
    "        # self.fc1 = nn.Linear(16 * 5 * 5, 120,)\n",
    "        self.flat = nn.Flatten(start_dim=1)\n",
    "        # 84 fully connected neurons\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        # 10 fully connected neurons\n",
    "        self.fc3 = nn.Linear(\n",
    "            84,\n",
    "            output_dim,\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        # x = x.view(-1, 1, 28, 28)\n",
    "        x = self.pool1(F.relu(self.conv1(x)))\n",
    "        x = self.pool2(F.relu(self.conv2(x)))\n",
    "        x = F.relu(self.conv3(x))\n",
    "        x = self.flat(x)\n",
    "        # x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class for FC-LeNet Network\n",
    "class FcLeNet(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super(FcLeNet, self).__init__()\n",
    "        # 6 kernels 5x5\n",
    "        self.fcconv1 = nn.Linear(input_dim, 3456)\n",
    "        # max-pooling over 2x2\n",
    "        self.pool1 = nn.MaxPool2d(2, stride=2)\n",
    "        # 16 kernels 5x5\n",
    "        self.fcconv2 = nn.Linear(864, 1024)\n",
    "        # max-pooling over 2x2\n",
    "        self.pool2 = nn.MaxPool2d(2, stride=2)\n",
    "        # 120 kernels 4x4 to match the dimensionality of the fully connected network\n",
    "        self.fcconv3 = nn.Linear(256, 120)\n",
    "        # 120 fully connected neurons, too many parameter in this case w.r.t. the paper\n",
    "        #self.fc1 = nn.Linear(16 * 5 * 5, 120,)\n",
    "        self.flat = nn.Flatten(start_dim=1)\n",
    "        # 84 fully connected neurons\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        # 10 fully connected neurons\n",
    "        self.fc3 = nn.Linear(84, output_dim,)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.flatten(x, start_dim=1)\n",
    "        x = self.pool1(F.relu(self.fcconv1(x)).view(-1,6,24,24))\n",
    "        x = self.flat(x)\n",
    "        x = self.pool2(F.relu(self.fcconv2(x)).view(-1,16,8,8))\n",
    "        x = self.flat(x)\n",
    "        x = F.relu(self.fcconv3(x))\n",
    "        #x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" # Class for FCTied-LeNet\n",
    "class FCTied_LeNet(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super(FCTied_LeNet, self).__init__()\n",
    "        # 6 kernels 5x5\n",
    "        self.conv1 = nn.Conv2d(input_dim, 6, 55, padding='same',)\n",
    "        # max-pooling over 2x2\n",
    "        self.pool1 = nn.MaxPool2d(2, stride=2)\n",
    "        # 16 kernels 5x5\n",
    "        self.conv2 = nn.Conv2d(6, 16, 27, padding='same')\n",
    "        # max-pooling over 2x2\n",
    "        self.pool2 = nn.MaxPool2d(2, stride=2)\n",
    "        # 120 kernels 4x4 to match the dimensionality of the fully connected network\n",
    "        self.conv3 = nn.Conv2d(16, 120, 7,)\n",
    "        # 120 fully connected neurons, too many parameter in this case w.r.t. the paper\n",
    "        #self.fc1 = nn.Linear(16 * 5 * 5, 120,)\n",
    "        self.flat = nn.Flatten(start_dim=1)\n",
    "        # 84 fully connected neurons\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        # 10 fully connected neurons\n",
    "        self.fc3 = nn.Linear(84, output_dim,)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 1, 28, 28)\n",
    "        x = self.pool1(F.relu(self.conv1(x)))\n",
    "        x = self.pool2(F.relu(self.conv2(x)))\n",
    "        x = F.relu(self.conv3(x))\n",
    "        x = self.flat(x)\n",
    "        #x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x \"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class for general FCTied-LeNet\n",
    "class FCTied_LeNet(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim, input_height, input_width):\n",
    "        super(FCTied_LeNet, self).__init__()\n",
    "        # 6 kernels (2*H-1)x(2*H-1)\n",
    "        self.conv1 = nn.Conv2d(\n",
    "            input_dim,\n",
    "            6,\n",
    "            2*input_height-1,\n",
    "            padding=\"same\",\n",
    "        )\n",
    "        # max-pooling over 2x2\n",
    "        self.pool1 = nn.MaxPool2d(2, stride=2)\n",
    "        # 16 kernels (H-1)x(H-1)\n",
    "        self.conv2 = nn.Conv2d(6, 16, input_height-1, padding=\"same\")\n",
    "        # max-pooling over 2x2\n",
    "        self.pool2 = nn.MaxPool2d(2, stride=2)\n",
    "        # 120 kernels 7x7 to match the dimensionality of the fully connected network\n",
    "        self.conv3 = nn.Conv2d(\n",
    "            16,\n",
    "            120,\n",
    "            int(input_height/4), # TODO: check if this is correct for cifar10 \n",
    "        )\n",
    "        # 120 fully connected neurons, too many parameter in this case w.r.t. the paper\n",
    "        # self.fc1 = nn.Linear(16 * 5 * 5, 120,)\n",
    "        self.flat = nn.Flatten(start_dim=1)\n",
    "        # 84 fully connected neurons\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        # 10 fully connected neurons\n",
    "        self.fc3 = nn.Linear(\n",
    "            84,\n",
    "            output_dim,\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x = x.view(-1, 1, 28, 28)\n",
    "        x = self.pool1(F.relu(self.conv1(x)))\n",
    "        x = self.pool2(F.relu(self.conv2(x)))\n",
    "        x = F.relu(self.conv3(x))\n",
    "        x = self.flat(x)\n",
    "        # x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of parameters:  199210\n"
     ]
    }
   ],
   "source": [
    "hidden_dim = 200\n",
    "num_layers = 1\n",
    "model = FullyConnectedNetwork(input_dim, hidden_dim, output_dim, num_layers)\n",
    "model.to(device)\n",
    "\n",
    "num_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(\"Number of parameters: \", num_params)\n",
    "\n",
    "#save information to file\n",
    "with open('results.txt', 'a') as f:\n",
    "    f.write(\"\\n##############################################\")\n",
    "    f.write(f\"\\nNumber_of_parameters: {num_params}\")\n",
    "    f.write(f\"\\nhidden_dim: {hidden_dim}\")\n",
    "    f.write(f\"\\nnum_layers: {num_layers}\")\n",
    "f.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32md:\\Antonio\\Sapienza\\Deep Learning & AAI\\Intrinsic_Dimension\\Intrinsic-Dimension\\intrinsic.ipynb Cella 17\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/Antonio/Sapienza/Deep%20Learning%20%26%20AAI/Intrinsic_Dimension/Intrinsic-Dimension/intrinsic.ipynb#X21sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m modules \u001b[39m=\u001b[39m [module \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m model\u001b[39m.\u001b[39mmodules()]\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Antonio/Sapienza/Deep%20Learning%20%26%20AAI/Intrinsic_Dimension/Intrinsic-Dimension/intrinsic.ipynb#X21sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39m# Print Model Summary\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Antonio/Sapienza/Deep%20Learning%20%26%20AAI/Intrinsic_Dimension/Intrinsic-Dimension/intrinsic.ipynb#X21sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mprint\u001b[39m(modules[\u001b[39m0\u001b[39m])\n",
      "\u001b[1;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "modules = [module for module in model.modules()]\n",
    "# Print Model Summary\n",
    "print(modules[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of parameters: 62006\n"
     ]
    }
   ],
   "source": [
    "model = LeNet(channel_in, output_dim)\n",
    "model.to(device)\n",
    "\n",
    "num_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(\"Number of parameters: %d\" % num_params)\n",
    "\n",
    "with open('results.txt', 'a') as f:\n",
    "    f.write(\"\\n##############################################\")\n",
    "    f.write(f\"\\nNumber_of_parameters: {num_params}\")\n",
    "    f.write(\"\\ntype: LeNet\")\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LeNet(\n",
      "  (conv1): Conv2d(3, 6, kernel_size=(5, 5), stride=(1, 1), padding=valid)\n",
      "  (pool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1), padding=valid)\n",
      "  (pool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (conv3): Conv2d(16, 120, kernel_size=(4, 4), stride=(1, 1))\n",
      "  (flat): Flatten(start_dim=1, end_dim=-1)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "modules = [module for module in model.modules()]\n",
    "# Print Model Summary\n",
    "print(modules[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of parameters: 658238\n"
     ]
    }
   ],
   "source": [
    "model = Untied_LeNet(channel_in, output_dim, input_height, input_width)\n",
    "model.to(device)\n",
    "\n",
    "num_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(\"Number of parameters: %d\" % num_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of parameters: 3640574\n"
     ]
    }
   ],
   "source": [
    "model = FcLeNet(input_dim, output_dim)\n",
    "model.to(device)\n",
    "\n",
    "num_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(\"Number of parameters: %d\" % num_params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FcLeNet(\n",
      "  (fcconv1): Linear(in_features=784, out_features=3456, bias=True)\n",
      "  (pool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (fcconv2): Linear(in_features=864, out_features=1024, bias=True)\n",
      "  (pool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (fcconv3): Linear(in_features=256, out_features=120, bias=True)\n",
      "  (flat): Flatten(start_dim=1, end_dim=-1)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "modules = [module for module in model.modules()]\n",
    "# Print Model Summary\n",
    "print(modules[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of parameters: 193370\n"
     ]
    }
   ],
   "source": [
    "model = FCTied_LeNet(channel_in, output_dim, input_height, input_width)\n",
    "model.to(device)\n",
    "\n",
    "num_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(\"Number of parameters: %d\" % num_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of parameters: 150\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "' with open(\\'results.txt\\', \\'a\\') as f:\\n    f.write(f\"\\nintrinsic_dim: {intrinsic_dim}\")\\nf.close() '"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "intrinsic_dim = 150\n",
    "model_intrinsic = DenseWrap(model, intrinsic_dimension=intrinsic_dim, device=device)\n",
    "num_params_intrinsic = sum(p.numel() for p in model_intrinsic.parameters() if p.requires_grad)\n",
    "print(\"Number of parameters: %d\" % num_params_intrinsic)\n",
    "\"\"\" with open('results.txt', 'a') as f:\n",
    "    f.write(f\"\\nintrinsic_dim: {intrinsic_dim}\")\n",
    "f.close() \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/469 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 6, 14, 14])\n",
      "torch.Size([128, 16, 7, 7])\n",
      "torch.Size([128, 120, 1, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [ 256/60000 \tLoss: 2.304115]:   0%|          | 1/469 [00:05<37:52,  4.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 6, 14, 14])\n",
      "torch.Size([128, 16, 7, 7])\n",
      "torch.Size([128, 120, 1, 1])\n",
      "torch.Size([128, 6, 14, 14])\n",
      "torch.Size([128, 16, 7, 7])\n",
      "torch.Size([128, 120, 1, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [ 512/60000 \tLoss: 2.305570]:   1%|          | 5/469 [00:05<05:20,  1.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 6, 14, 14])\n",
      "torch.Size([128, 16, 7, 7])\n",
      "torch.Size([128, 120, 1, 1])\n",
      "torch.Size([128, 6, 14, 14])\n",
      "torch.Size([128, 16, 7, 7])\n",
      "torch.Size([128, 120, 1, 1])\n",
      "torch.Size([128, 6, 14, 14])\n",
      "torch.Size([128, 16, 7, 7])\n",
      "torch.Size([128, 120, 1, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [ 896/60000 \tLoss: 2.305803]:   1%|         | 6/469 [00:05<04:08,  1.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 6, 14, 14])\n",
      "torch.Size([128, 16, 7, 7])\n",
      "torch.Size([128, 120, 1, 1])\n",
      "torch.Size([128, 6, 14, 14])\n",
      "torch.Size([128, 16, 7, 7])\n",
      "torch.Size([128, 120, 1, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [ 1152/60000 \tLoss: 2.308791]:   2%|         | 9/469 [00:05<02:12,  3.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 6, 14, 14])\n",
      "torch.Size([128, 16, 7, 7])\n",
      "torch.Size([128, 120, 1, 1])\n",
      "torch.Size([128, 6, 14, 14])\n",
      "torch.Size([128, 16, 7, 7])\n",
      "torch.Size([128, 120, 1, 1])\n",
      "torch.Size([128, 6, 14, 14])\n",
      "torch.Size([128, 16, 7, 7])\n",
      "torch.Size([128, 120, 1, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [ 1536/60000 \tLoss: 2.296549]:   3%|         | 12/469 [00:06<01:25,  5.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 6, 14, 14])\n",
      "torch.Size([128, 16, 7, 7])\n",
      "torch.Size([128, 120, 1, 1])\n",
      "torch.Size([128, 6, 14, 14])\n",
      "torch.Size([128, 16, 7, 7])\n",
      "torch.Size([128, 120, 1, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [ 1792/60000 \tLoss: 2.303747]:   3%|         | 14/469 [00:06<01:09,  6.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 6, 14, 14])\n",
      "torch.Size([128, 16, 7, 7])\n",
      "torch.Size([128, 120, 1, 1])\n",
      "torch.Size([128, 6, 14, 14])\n",
      "torch.Size([128, 16, 7, 7])\n",
      "torch.Size([128, 120, 1, 1])\n",
      "torch.Size([128, 6, 14, 14])\n",
      "torch.Size([128, 16, 7, 7])\n",
      "torch.Size([128, 120, 1, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [ 2048/60000 \tLoss: 2.306592]:   3%|         | 16/469 [00:06<00:57,  7.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 6, 14, 14])\n",
      "torch.Size([128, 16, 7, 7])\n",
      "torch.Size([128, 120, 1, 1])\n",
      "torch.Size([128, 6, 14, 14])\n",
      "torch.Size([128, 16, 7, 7])\n",
      "torch.Size([128, 120, 1, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [ 2432/60000 \tLoss: 2.304590]:   4%|         | 18/469 [00:06<00:54,  8.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 6, 14, 14])\n",
      "torch.Size([128, 16, 7, 7])\n",
      "torch.Size([128, 120, 1, 1])\n",
      "torch.Size([128, 6, 14, 14])\n",
      "torch.Size([128, 16, 7, 7])\n",
      "torch.Size([128, 120, 1, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [ 2688/60000 \tLoss: 2.313763]:   5%|         | 22/469 [00:06<00:48,  9.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 6, 14, 14])\n",
      "torch.Size([128, 16, 7, 7])\n",
      "torch.Size([128, 120, 1, 1])\n",
      "torch.Size([128, 6, 14, 14])\n",
      "torch.Size([128, 16, 7, 7])\n",
      "torch.Size([128, 120, 1, 1])\n",
      "torch.Size([128, 6, 14, 14])\n",
      "torch.Size([128, 16, 7, 7])\n",
      "torch.Size([128, 120, 1, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [ 2944/60000 \tLoss: 2.303157]:   5%|         | 24/469 [00:07<00:48,  9.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 6, 14, 14])\n",
      "torch.Size([128, 16, 7, 7])\n",
      "torch.Size([128, 120, 1, 1])\n",
      "torch.Size([128, 6, 14, 14])\n",
      "torch.Size([128, 16, 7, 7])\n",
      "torch.Size([128, 120, 1, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [ 3200/60000 \tLoss: 2.304145]:   6%|         | 26/469 [00:07<00:46,  9.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 6, 14, 14])\n",
      "torch.Size([128, 16, 7, 7])\n",
      "torch.Size([128, 120, 1, 1])\n",
      "torch.Size([128, 6, 14, 14])\n",
      "torch.Size([128, 16, 7, 7])\n",
      "torch.Size([128, 120, 1, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [ 3584/60000 \tLoss: 2.300012]:   6%|         | 28/469 [00:07<00:46,  9.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 6, 14, 14])\n",
      "torch.Size([128, 16, 7, 7])\n",
      "torch.Size([128, 120, 1, 1])\n",
      "torch.Size([128, 6, 14, 14])\n",
      "torch.Size([128, 16, 7, 7])\n",
      "torch.Size([128, 120, 1, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [ 3840/60000 \tLoss: 2.300860]:   6%|         | 30/469 [00:07<00:45,  9.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 6, 14, 14])\n",
      "torch.Size([128, 16, 7, 7])\n",
      "torch.Size([128, 120, 1, 1])\n",
      "torch.Size([128, 6, 14, 14])\n",
      "torch.Size([128, 16, 7, 7])\n",
      "torch.Size([128, 120, 1, 1])\n",
      "torch.Size([128, 6, 14, 14])\n",
      "torch.Size([128, 16, 7, 7])\n",
      "torch.Size([128, 120, 1, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [ 4096/60000 \tLoss: 2.310844]:   7%|         | 32/469 [00:08<00:42, 10.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 6, 14, 14])\n",
      "torch.Size([128, 16, 7, 7])\n",
      "torch.Size([128, 120, 1, 1])\n",
      "torch.Size([128, 6, 14, 14])\n",
      "torch.Size([128, 16, 7, 7])\n",
      "torch.Size([128, 120, 1, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [ 4480/60000 \tLoss: 2.306971]:   7%|         | 34/469 [00:08<00:44,  9.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 6, 14, 14])\n",
      "torch.Size([128, 16, 7, 7])\n",
      "torch.Size([128, 120, 1, 1])\n",
      "torch.Size([128, 6, 14, 14])\n",
      "torch.Size([128, 16, 7, 7])\n",
      "torch.Size([128, 120, 1, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [ 4608/60000 \tLoss: 2.306804]:   8%|         | 36/469 [00:08<00:43,  9.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 6, 14, 14])\n",
      "torch.Size([128, 16, 7, 7])\n",
      "torch.Size([128, 120, 1, 1])\n",
      "torch.Size([128, 6, 14, 14])\n",
      "torch.Size([128, 16, 7, 7])\n",
      "torch.Size([128, 120, 1, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [ 4992/60000 \tLoss: 2.308984]:   9%|         | 40/469 [00:08<00:44,  9.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 6, 14, 14])\n",
      "torch.Size([128, 16, 7, 7])\n",
      "torch.Size([128, 120, 1, 1])\n",
      "torch.Size([128, 6, 14, 14])\n",
      "torch.Size([128, 16, 7, 7])\n",
      "torch.Size([128, 120, 1, 1])\n",
      "torch.Size([128, 6, 14, 14])\n",
      "torch.Size([128, 16, 7, 7])\n",
      "torch.Size([128, 120, 1, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [ 5376/60000 \tLoss: 2.303328]:   9%|         | 42/469 [00:09<00:42, 10.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 6, 14, 14])\n",
      "torch.Size([128, 16, 7, 7])\n",
      "torch.Size([128, 120, 1, 1])\n",
      "torch.Size([128, 6, 14, 14])\n",
      "torch.Size([128, 16, 7, 7])\n",
      "torch.Size([128, 120, 1, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [ 5632/60000 \tLoss: 2.306914]:   9%|         | 44/469 [00:09<00:42,  9.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 6, 14, 14])\n",
      "torch.Size([128, 16, 7, 7])\n",
      "torch.Size([128, 120, 1, 1])\n",
      "torch.Size([128, 6, 14, 14])\n",
      "torch.Size([128, 16, 7, 7])\n",
      "torch.Size([128, 120, 1, 1])\n",
      "torch.Size([128, 6, 14, 14])\n",
      "torch.Size([128, 16, 7, 7])\n",
      "torch.Size([128, 120, 1, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [ 6016/60000 \tLoss: 2.315522]:  10%|         | 46/469 [00:09<00:43,  9.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 6, 14, 14])\n",
      "torch.Size([128, 16, 7, 7])\n",
      "torch.Size([128, 120, 1, 1])\n",
      "torch.Size([128, 6, 14, 14])\n",
      "torch.Size([128, 16, 7, 7])\n",
      "torch.Size([128, 120, 1, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [ 6272/60000 \tLoss: 2.304799]:  10%|         | 49/469 [00:09<00:43,  9.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 6, 14, 14])\n",
      "torch.Size([128, 16, 7, 7])\n",
      "torch.Size([128, 120, 1, 1])\n",
      "torch.Size([128, 6, 14, 14])\n",
      "torch.Size([128, 16, 7, 7])\n",
      "torch.Size([128, 120, 1, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [ 6528/60000 \tLoss: 2.302814]:  11%|         | 51/469 [00:09<00:42,  9.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 6, 14, 14])\n",
      "torch.Size([128, 16, 7, 7])\n",
      "torch.Size([128, 120, 1, 1])\n",
      "torch.Size([128, 6, 14, 14])\n",
      "torch.Size([128, 16, 7, 7])\n",
      "torch.Size([128, 120, 1, 1])\n",
      "torch.Size([128, 6, 14, 14])\n",
      "torch.Size([128, 16, 7, 7])\n",
      "torch.Size([128, 120, 1, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [ 6912/60000 \tLoss: 2.302817]:  11%|        | 53/469 [00:10<00:40, 10.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 6, 14, 14])\n",
      "torch.Size([128, 16, 7, 7])\n",
      "torch.Size([128, 120, 1, 1])\n",
      "torch.Size([128, 6, 14, 14])\n",
      "torch.Size([128, 16, 7, 7])\n",
      "torch.Size([128, 120, 1, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [ 7168/60000 \tLoss: 2.298508]:  12%|        | 57/469 [00:10<00:40, 10.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 6, 14, 14])\n",
      "torch.Size([128, 16, 7, 7])\n",
      "torch.Size([128, 120, 1, 1])\n",
      "torch.Size([128, 6, 14, 14])\n",
      "torch.Size([128, 16, 7, 7])\n",
      "torch.Size([128, 120, 1, 1])\n",
      "torch.Size([128, 6, 14, 14])\n",
      "torch.Size([128, 16, 7, 7])\n",
      "torch.Size([128, 120, 1, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [ 7424/60000 \tLoss: 2.311059]:  13%|        | 59/469 [00:10<00:40, 10.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 6, 14, 14])\n",
      "torch.Size([128, 16, 7, 7])\n",
      "torch.Size([128, 120, 1, 1])\n",
      "torch.Size([128, 6, 14, 14])\n",
      "torch.Size([128, 16, 7, 7])\n",
      "torch.Size([128, 120, 1, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [ 7808/60000 \tLoss: 2.307916]:  13%|        | 61/469 [00:10<00:40, 10.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 6, 14, 14])\n",
      "torch.Size([128, 16, 7, 7])\n",
      "torch.Size([128, 120, 1, 1])\n",
      "torch.Size([128, 6, 14, 14])\n",
      "torch.Size([128, 16, 7, 7])\n",
      "torch.Size([128, 120, 1, 1])\n",
      "torch.Size([128, 6, 14, 14])\n",
      "torch.Size([128, 16, 7, 7])\n",
      "torch.Size([128, 120, 1, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [ 8192/60000 \tLoss: 2.304815]:  13%|        | 63/469 [00:11<00:39, 10.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 6, 14, 14])\n",
      "torch.Size([128, 16, 7, 7])\n",
      "torch.Size([128, 120, 1, 1])\n",
      "torch.Size([128, 6, 14, 14])\n",
      "torch.Size([128, 16, 7, 7])\n",
      "torch.Size([128, 120, 1, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [ 8448/60000 \tLoss: 2.305084]:  14%|        | 67/469 [00:11<00:39, 10.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 6, 14, 14])\n",
      "torch.Size([128, 16, 7, 7])\n",
      "torch.Size([128, 120, 1, 1])\n",
      "torch.Size([128, 6, 14, 14])\n",
      "torch.Size([128, 16, 7, 7])\n",
      "torch.Size([128, 120, 1, 1])\n",
      "torch.Size([128, 6, 14, 14])\n",
      "torch.Size([128, 16, 7, 7])\n",
      "torch.Size([128, 120, 1, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [ 8832/60000 \tLoss: 2.307948]:  15%|        | 69/469 [00:11<00:37, 10.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 6, 14, 14])\n",
      "torch.Size([128, 16, 7, 7])\n",
      "torch.Size([128, 120, 1, 1])\n",
      "torch.Size([128, 6, 14, 14])\n",
      "torch.Size([128, 16, 7, 7])\n",
      "torch.Size([128, 120, 1, 1])\n",
      "torch.Size([128, 6, 14, 14])\n",
      "torch.Size([128, 16, 7, 7])\n",
      "torch.Size([128, 120, 1, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [ 9216/60000 \tLoss: 2.302308]:  15%|        | 71/469 [00:12<00:39, 10.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 6, 14, 14])\n",
      "torch.Size([128, 16, 7, 7])\n",
      "torch.Size([128, 120, 1, 1])\n",
      "torch.Size([128, 6, 14, 14])\n",
      "torch.Size([128, 16, 7, 7])\n",
      "torch.Size([128, 120, 1, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [ 9472/60000 \tLoss: 2.304272]:  16%|        | 75/469 [00:12<00:37, 10.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 6, 14, 14])\n",
      "torch.Size([128, 16, 7, 7])\n",
      "torch.Size([128, 120, 1, 1])\n",
      "torch.Size([128, 6, 14, 14])\n",
      "torch.Size([128, 16, 7, 7])\n",
      "torch.Size([128, 120, 1, 1])\n",
      "torch.Size([128, 6, 14, 14])\n",
      "torch.Size([128, 16, 7, 7])\n",
      "torch.Size([128, 120, 1, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [ 9856/60000 \tLoss: 2.306057]:  16%|        | 77/469 [00:12<00:38, 10.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 6, 14, 14])\n",
      "torch.Size([128, 16, 7, 7])\n",
      "torch.Size([128, 120, 1, 1])\n",
      "torch.Size([128, 6, 14, 14])\n",
      "torch.Size([128, 16, 7, 7])\n",
      "torch.Size([128, 120, 1, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [ 10112/60000 \tLoss: 2.306677]:  17%|        | 79/469 [00:12<00:38, 10.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 6, 14, 14])\n",
      "torch.Size([128, 16, 7, 7])\n",
      "torch.Size([128, 120, 1, 1])\n",
      "torch.Size([128, 6, 14, 14])\n",
      "torch.Size([128, 16, 7, 7])\n",
      "torch.Size([128, 120, 1, 1])\n",
      "torch.Size([128, 6, 14, 14])\n",
      "torch.Size([128, 16, 7, 7])\n",
      "torch.Size([128, 120, 1, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [ 10496/60000 \tLoss: 2.297417]:  17%|        | 81/469 [00:13<00:39,  9.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 6, 14, 14])\n",
      "torch.Size([128, 16, 7, 7])\n",
      "torch.Size([128, 120, 1, 1])\n",
      "torch.Size([128, 6, 14, 14])\n",
      "torch.Size([128, 16, 7, 7])\n",
      "torch.Size([128, 120, 1, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [ 10752/60000 \tLoss: 2.307107]:  18%|        | 85/469 [00:13<00:36, 10.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 6, 14, 14])\n",
      "torch.Size([128, 16, 7, 7])\n",
      "torch.Size([128, 120, 1, 1])\n",
      "torch.Size([128, 6, 14, 14])\n",
      "torch.Size([128, 16, 7, 7])\n",
      "torch.Size([128, 120, 1, 1])\n",
      "torch.Size([128, 6, 14, 14])\n",
      "torch.Size([128, 16, 7, 7])\n",
      "torch.Size([128, 120, 1, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [ 11136/60000 \tLoss: 2.300551]:  19%|        | 87/469 [00:13<00:38,  9.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 6, 14, 14])\n",
      "torch.Size([128, 16, 7, 7])\n",
      "torch.Size([128, 120, 1, 1])\n",
      "torch.Size([128, 6, 14, 14])\n",
      "torch.Size([128, 16, 7, 7])\n",
      "torch.Size([128, 120, 1, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [ 11392/60000 \tLoss: 2.295885]:  19%|        | 89/469 [00:13<00:38,  9.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 6, 14, 14])\n",
      "torch.Size([128, 16, 7, 7])\n",
      "torch.Size([128, 120, 1, 1])\n",
      "torch.Size([128, 6, 14, 14])\n",
      "torch.Size([128, 16, 7, 7])\n",
      "torch.Size([128, 120, 1, 1])\n",
      "torch.Size([128, 6, 14, 14])\n",
      "torch.Size([128, 16, 7, 7])\n",
      "torch.Size([128, 120, 1, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [ 11776/60000 \tLoss: 2.300969]:  19%|        | 91/469 [00:14<00:37, 10.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 6, 14, 14])\n",
      "torch.Size([128, 16, 7, 7])\n",
      "torch.Size([128, 120, 1, 1])\n",
      "torch.Size([128, 6, 14, 14])\n",
      "torch.Size([128, 16, 7, 7])\n",
      "torch.Size([128, 120, 1, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [ 12032/60000 \tLoss: 2.306979]:  20%|        | 95/469 [00:14<00:55,  6.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 6, 14, 14])\n",
      "torch.Size([128, 16, 7, 7])\n",
      "torch.Size([128, 120, 1, 1])\n",
      "torch.Size([128, 6, 14, 14])\n",
      "torch.Size([128, 16, 7, 7])\n",
      "torch.Size([128, 120, 1, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32md:\\Antonio\\Sapienza\\Deep Learning & AAI\\Intrinsic_Dimension\\Intrinsic-Dimension\\intrinsic.ipynb Cella 26\u001b[0m in \u001b[0;36m<cell line: 88>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Antonio/Sapienza/Deep%20Learning%20%26%20AAI/Intrinsic_Dimension/Intrinsic-Dimension/intrinsic.ipynb#X34sZmlsZQ%3D%3D?line=94'>95</a>\u001b[0m best_acc, best_epoch \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m, \u001b[39m0\u001b[39m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Antonio/Sapienza/Deep%20Learning%20%26%20AAI/Intrinsic_Dimension/Intrinsic-Dimension/intrinsic.ipynb#X34sZmlsZQ%3D%3D?line=95'>96</a>\u001b[0m \u001b[39mfor\u001b[39;00m epoch \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m1\u001b[39m, \u001b[39m101\u001b[39m):\n\u001b[1;32m---> <a href='vscode-notebook-cell:/d%3A/Antonio/Sapienza/Deep%20Learning%20%26%20AAI/Intrinsic_Dimension/Intrinsic-Dimension/intrinsic.ipynb#X34sZmlsZQ%3D%3D?line=96'>97</a>\u001b[0m     train(model_intrinsic, train_dataloader, optimizer, epoch)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Antonio/Sapienza/Deep%20Learning%20%26%20AAI/Intrinsic_Dimension/Intrinsic-Dimension/intrinsic.ipynb#X34sZmlsZQ%3D%3D?line=97'>98</a>\u001b[0m     accuracy \u001b[39m=\u001b[39m test(model_intrinsic, test_dataloader)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Antonio/Sapienza/Deep%20Learning%20%26%20AAI/Intrinsic_Dimension/Intrinsic-Dimension/intrinsic.ipynb#X34sZmlsZQ%3D%3D?line=98'>99</a>\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mValidation Accuracy: \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(accuracy))\n",
      "\u001b[1;32md:\\Antonio\\Sapienza\\Deep Learning & AAI\\Intrinsic_Dimension\\Intrinsic-Dimension\\intrinsic.ipynb Cella 26\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(model, train_loader, optimizer, epoch)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Antonio/Sapienza/Deep%20Learning%20%26%20AAI/Intrinsic_Dimension/Intrinsic-Dimension/intrinsic.ipynb#X34sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m tqdm_iterator \u001b[39m=\u001b[39m tqdm(\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Antonio/Sapienza/Deep%20Learning%20%26%20AAI/Intrinsic_Dimension/Intrinsic-Dimension/intrinsic.ipynb#X34sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m     \u001b[39menumerate\u001b[39m(train_loader),\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Antonio/Sapienza/Deep%20Learning%20%26%20AAI/Intrinsic_Dimension/Intrinsic-Dimension/intrinsic.ipynb#X34sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m     total\u001b[39m=\u001b[39m\u001b[39mlen\u001b[39m(train_loader),\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Antonio/Sapienza/Deep%20Learning%20%26%20AAI/Intrinsic_Dimension/Intrinsic-Dimension/intrinsic.ipynb#X34sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m     desc\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Antonio/Sapienza/Deep%20Learning%20%26%20AAI/Intrinsic_Dimension/Intrinsic-Dimension/intrinsic.ipynb#X34sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m     leave\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m,)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Antonio/Sapienza/Deep%20Learning%20%26%20AAI/Intrinsic_Dimension/Intrinsic-Dimension/intrinsic.ipynb#X34sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m len_tr_dl_ds \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(train_loader\u001b[39m.\u001b[39mdataset)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/d%3A/Antonio/Sapienza/Deep%20Learning%20%26%20AAI/Intrinsic_Dimension/Intrinsic-Dimension/intrinsic.ipynb#X34sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m \u001b[39mfor\u001b[39;00m batch_idx, (data, target) \u001b[39min\u001b[39;00m tqdm_iterator:\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Antonio/Sapienza/Deep%20Learning%20%26%20AAI/Intrinsic_Dimension/Intrinsic-Dimension/intrinsic.ipynb#X34sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m     data, target \u001b[39m=\u001b[39m data\u001b[39m.\u001b[39mto(device, non_blocking\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m), target\u001b[39m.\u001b[39mto(device, non_blocking\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Antonio/Sapienza/Deep%20Learning%20%26%20AAI/Intrinsic_Dimension/Intrinsic-Dimension/intrinsic.ipynb#X34sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m     output \u001b[39m=\u001b[39m model(data)\n",
      "File \u001b[1;32md:\\Antonio\\python\\lib\\site-packages\\tqdm\\std.py:1195\u001b[0m, in \u001b[0;36mtqdm.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1192\u001b[0m time \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_time\n\u001b[0;32m   1194\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 1195\u001b[0m     \u001b[39mfor\u001b[39;00m obj \u001b[39min\u001b[39;00m iterable:\n\u001b[0;32m   1196\u001b[0m         \u001b[39myield\u001b[39;00m obj\n\u001b[0;32m   1197\u001b[0m         \u001b[39m# Update and possibly print the progressbar.\u001b[39;00m\n\u001b[0;32m   1198\u001b[0m         \u001b[39m# Note: does not call self.update(1) for speed optimisation.\u001b[39;00m\n",
      "File \u001b[1;32md:\\Antonio\\python\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:530\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    528\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sampler_iter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    529\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()\n\u001b[1;32m--> 530\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next_data()\n\u001b[0;32m    531\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m    532\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable \u001b[39mand\u001b[39;00m \\\n\u001b[0;32m    533\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \\\n\u001b[0;32m    534\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[1;32md:\\Antonio\\python\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:570\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    568\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_next_data\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m    569\u001b[0m     index \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_next_index()  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m--> 570\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dataset_fetcher\u001b[39m.\u001b[39;49mfetch(index)  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    571\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory:\n\u001b[0;32m    572\u001b[0m         data \u001b[39m=\u001b[39m _utils\u001b[39m.\u001b[39mpin_memory\u001b[39m.\u001b[39mpin_memory(data)\n",
      "File \u001b[1;32md:\\Antonio\\python\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:49\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     47\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfetch\u001b[39m(\u001b[39mself\u001b[39m, possibly_batched_index):\n\u001b[0;32m     48\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mauto_collation:\n\u001b[1;32m---> 49\u001b[0m         data \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[idx] \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     50\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     51\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[1;32md:\\Antonio\\python\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:49\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     47\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfetch\u001b[39m(\u001b[39mself\u001b[39m, possibly_batched_index):\n\u001b[0;32m     48\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mauto_collation:\n\u001b[1;32m---> 49\u001b[0m         data \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdataset[idx] \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     50\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     51\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[1;32md:\\Antonio\\python\\lib\\site-packages\\torchvision\\datasets\\mnist.py:145\u001b[0m, in \u001b[0;36mMNIST.__getitem__\u001b[1;34m(self, index)\u001b[0m\n\u001b[0;32m    142\u001b[0m img \u001b[39m=\u001b[39m Image\u001b[39m.\u001b[39mfromarray(img\u001b[39m.\u001b[39mnumpy(), mode\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mL\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    144\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtransform \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 145\u001b[0m     img \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtransform(img)\n\u001b[0;32m    147\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtarget_transform \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    148\u001b[0m     target \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtarget_transform(target)\n",
      "File \u001b[1;32md:\\Antonio\\python\\lib\\site-packages\\torchvision\\transforms\\transforms.py:95\u001b[0m, in \u001b[0;36mCompose.__call__\u001b[1;34m(self, img)\u001b[0m\n\u001b[0;32m     93\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, img):\n\u001b[0;32m     94\u001b[0m     \u001b[39mfor\u001b[39;00m t \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtransforms:\n\u001b[1;32m---> 95\u001b[0m         img \u001b[39m=\u001b[39m t(img)\n\u001b[0;32m     96\u001b[0m     \u001b[39mreturn\u001b[39;00m img\n",
      "File \u001b[1;32md:\\Antonio\\python\\lib\\site-packages\\torchvision\\transforms\\transforms.py:135\u001b[0m, in \u001b[0;36mToTensor.__call__\u001b[1;34m(self, pic)\u001b[0m\n\u001b[0;32m    127\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, pic):\n\u001b[0;32m    128\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    129\u001b[0m \u001b[39m    Args:\u001b[39;00m\n\u001b[0;32m    130\u001b[0m \u001b[39m        pic (PIL Image or numpy.ndarray): Image to be converted to tensor.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    133\u001b[0m \u001b[39m        Tensor: Converted image.\u001b[39;00m\n\u001b[0;32m    134\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 135\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mto_tensor(pic)\n",
      "File \u001b[1;32md:\\Antonio\\python\\lib\\site-packages\\torchvision\\transforms\\functional.py:155\u001b[0m, in \u001b[0;36mto_tensor\u001b[1;34m(pic)\u001b[0m\n\u001b[0;32m    153\u001b[0m img \u001b[39m=\u001b[39m img\u001b[39m.\u001b[39mpermute((\u001b[39m2\u001b[39m, \u001b[39m0\u001b[39m, \u001b[39m1\u001b[39m))\u001b[39m.\u001b[39mcontiguous()\n\u001b[0;32m    154\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(img, torch\u001b[39m.\u001b[39mByteTensor):\n\u001b[1;32m--> 155\u001b[0m     \u001b[39mreturn\u001b[39;00m img\u001b[39m.\u001b[39;49mto(dtype\u001b[39m=\u001b[39;49mdefault_float_dtype)\u001b[39m.\u001b[39mdiv(\u001b[39m255\u001b[39m)\n\u001b[0;32m    156\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    157\u001b[0m     \u001b[39mreturn\u001b[39;00m img\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#torch.autograd.set_detect_anomaly(True) #this line can have huge performance impact\n",
    "# train the model\n",
    "from logging import raiseExceptions\n",
    "\n",
    "# training step\n",
    "\n",
    "def train(model, train_loader, optimizer, epoch):\n",
    "    model.train()\n",
    "    #train_loss_averager = make_averager()  # mantain a running average of the loss\n",
    "\n",
    "    # TRAIN\n",
    "    tqdm_iterator = tqdm(\n",
    "        enumerate(train_loader),\n",
    "        total=len(train_loader),\n",
    "        desc=\"\",\n",
    "        leave=True,)\n",
    "\n",
    "    len_tr_dl_ds = len(train_loader.dataset)\n",
    "\n",
    "    for batch_idx, (data, target) in tqdm_iterator:\n",
    "        data, target = data.to(device, non_blocking=True), target.to(device, non_blocking=True)\n",
    "        output = model(data)\n",
    "        loss = F.cross_entropy(output, target)\n",
    "        model.zero_grad(set_to_none=True)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad(set_to_none=True)\n",
    "\n",
    "        #train_loss_averager(loss.item())\n",
    "        tqdm_iterator.set_description(\n",
    "            f\"Train Epoch: {epoch} [ {batch_idx * len(data)}/{len_tr_dl_ds} \\tLoss: {loss.item():.6f}]\"\n",
    "        )\n",
    "        tqdm_iterator.refresh()  # to show immediately the update\n",
    "    tqdm_iterator.close()\n",
    "\n",
    "    if np.isnan(loss.item()):\n",
    "        print(\"Loss is nan\")\n",
    "        raise Exception(\"Loss is nan\")\n",
    "        exit()\n",
    "\n",
    "\n",
    "# testing step\n",
    "def test(model, test_loader):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "\n",
    "    tqdm_iterator = tqdm(\n",
    "        enumerate(test_loader),\n",
    "        total=len(test_loader),\n",
    "        desc=\"\",\n",
    "        leave=True,)\n",
    "\n",
    "    len_ts_dl_ds = len(test_loader.dataset)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (data, target) in tqdm_iterator:\n",
    "            data, target = data.to(device, non_blocking=True), target.to(device, non_blocking=True)\n",
    "            output = model(data)\n",
    "            test_loss += F.cross_entropy(output, target).item()  # sum up batch loss\n",
    "            # get the index of the max probability\n",
    "            pred = output.max(1, keepdim=True)[1]\n",
    "            correct += pred.eq(target.view_as(pred)).cpu().sum().item()\n",
    "            tqdm_iterator.set_description(\n",
    "            f\"Test Epoch: {epoch} [{batch_idx * len(data)}/{len_ts_dl_ds} \\tLoss: {test_loss:.6f}, Accuracy: {correct}/{len_ts_dl_ds} ({100.0 * correct / len_ts_dl_ds}%)\"\n",
    "        )\n",
    "    tqdm_iterator.refresh()  # to show immediately the update\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    print(f\"Validation Average loss: {test_loss:.6f}\")\n",
    "    \n",
    "    tqdm_iterator.close()\n",
    "    \n",
    "    # show an histogram of the weights of the model\n",
    "    \"\"\"start = -1\n",
    "    stop = 1\n",
    "    bins = 30\n",
    "    for param in model.parameters():\n",
    "        if param.requires_grad:\n",
    "            \n",
    "            hist = torch.histc(param.data, bins = bins, min = start, max = stop)\n",
    "            x = np.arange(start, stop, (stop-start)/bins)\n",
    "            plt.bar(x, hist.cpu(), align='center')\n",
    "            plt.ylabel('Frequency')\n",
    "            plt.show() \"\"\"\n",
    "\n",
    "    return correct / len(test_loader.dataset)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    learning_rate = 0.01\n",
    "    optimizer = optim.SGD(model_intrinsic.parameters(), lr=learning_rate)\n",
    "    # download and load MNIST Dataset\n",
    "    train_dataloader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers = 0, pin_memory=True,) #persistent_workers=True)\n",
    "    test_dataloader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers = 0, pin_memory=True,) #persistent_workers=True)\n",
    "    # train the model\n",
    "    best_acc, best_epoch = 0, 0\n",
    "    for epoch in range(1, 101):\n",
    "        train(model_intrinsic, train_dataloader, optimizer, epoch)\n",
    "        accuracy = test(model_intrinsic, test_dataloader)\n",
    "        print(\"Validation Accuracy: {}\".format(accuracy))\n",
    "        #save information to file\n",
    "        \"\"\" with open('results.txt', 'a') as f:\n",
    "            f.write(f\"\\nEpoch: {epoch}\")\n",
    "            f.write(f\"\\nValidation Accuracy: {accuracy}\")\n",
    "        f.close() \"\"\"\n",
    "        if accuracy > best_acc:\n",
    "            best_acc = accuracy\n",
    "            best_epoch = epoch\n",
    "            if best_acc >= 0.90:\n",
    "                torch.save(model_intrinsic.state_dict(), f\"lenet_mnist_{intrinsic_dim}.pt\")\n",
    "                #torch.save(model_intrinsic.state_dict(), f\"model_best_h{hidden_dim}_id{intrinsic_dim}_lay{num_layers}.pt\")\n",
    "                \"\"\" j = None\n",
    "                with open('results.json', 'r') as f:\n",
    "                    j = json.load(f)\n",
    "                f.close()\n",
    "                with open('results.json', 'w') as f:\n",
    "                    j[f\"fcmodel_h{hidden_dim}_id{intrinsic_dim}_lay{num_layers}\"] = {\"number_parameter\": num_params, \"hidden_dimension\": hidden_dim, \"number_layers\": num_layers, \"intrinsic_dimension\": intrinsic_dim, \"epoch\": epoch, \"validation_accuracy\": accuracy}\n",
    "                    json.dump(j, f, indent=4, separators=(',', ': ')) \n",
    "                break \"\"\"\n",
    "\n",
    "    \"\"\" j = None\n",
    "    with open('results_lenet.json', 'r') as f:\n",
    "        j = json.load(f)\n",
    "    f.close()\n",
    "    with open('results_lenet.json', 'w') as f:\n",
    "        j[f\"lenet_model_id{intrinsic_dim}_lr{learning_rate}\"] = {\"number_parameter\": num_params, \"intrinsic_dimension\": intrinsic_dim, \"epoch\": epoch, \n",
    "        \"validation_accuracy\": accuracy, \"learning_rate\": learning_rate, \"best_epoch\": best_epoch, \"best_accuracy\": best_acc}\n",
    "        json.dump(j, f, indent=4, separators=(',', ': '))\n",
    "    f.close() \"\"\"\n",
    "\n",
    "    \"\"\" j = None\n",
    "    with open('results_lenet.json', 'r') as f:\n",
    "        j = json.load(f)\n",
    "    f.close()\n",
    "    with open('results_lenet.json', 'w') as f:\n",
    "        j[f\"fcmodel_h{hidden_dim}_id{intrinsic_dim}_lay{num_layers}_lr{learning_rate}\"] = {\"number_parameter\": num_params, \n",
    "        \"hidden_dimension\": hidden_dim, \"number_layers\": num_layers, \"intrinsic_dimension\": intrinsic_dim, \"epoch\": epoch, \n",
    "        \"validation_accuracy\": accuracy, \"learning_rate\": learning_rate, \"best_epoch\": best_epoch, \"best_accuracy\": best_acc}\n",
    "        json.dump(j, f, indent=4, separators=(',', ': '))\n",
    "    f.close() \"\"\"\n",
    "\"\"\"     j = None\n",
    "    with open('results.json', 'r') as f:\n",
    "        j = json.load(f)\n",
    "    f.close()\n",
    "    with open('results.json', 'w') as f:\n",
    "        j[f\"fcmodel_h{hidden_dim}_id{intrinsic_dim}_lay{num_layers}\"] = {\"number_parameter\": num_params, \"hidden_dimension\": hidden_dim, \"number_layers\": num_layers, \"intrinsic_dimension\": intrinsic_dim, \"epoch\": epoch, \"validation_accuracy\": accuracy}\n",
    "        json.dump(j, f, indent=4, separators=(',', ': ')) \"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "error_y": {
          "array": [
           1,
           2,
           3,
           4,
           5
          ],
          "type": "data",
          "visible": true
         },
         "marker": {
          "color": [
           1,
           2,
           3,
           4,
           5
          ],
          "showscale": true,
          "size": 30
         },
         "mode": "markers",
         "name": "layer width: 50",
         "type": "scatter",
         "x": [
          1,
          3.2,
          5.4,
          7.6,
          9.8
         ],
         "y": [
          1,
          3.2,
          5.4,
          7.6,
          9.8
         ]
        },
        {
         "error_y": {
          "array": [
           1,
           2,
           3,
           4,
           5
          ],
          "type": "data",
          "visible": true
         },
         "marker": {
          "color": [
           1,
           2,
           3,
           4,
           5
          ],
          "showscale": true,
          "size": 55
         },
         "mode": "markers",
         "name": "layer width: 100",
         "type": "scatter",
         "x": [
          1,
          3.2,
          5.4,
          7.6,
          9.8
         ],
         "y": [
          1,
          3.2,
          5.4,
          7.6,
          9.8
         ]
        },
        {
         "error_y": {
          "array": [
           1,
           2,
           3,
           4,
           5
          ],
          "type": "data",
          "visible": true
         },
         "marker": {
          "color": [
           1,
           2,
           3,
           4,
           5
          ],
          "showscale": true,
          "size": 70
         },
         "mode": "markers",
         "name": "layer width: 200",
         "type": "scatter",
         "x": [
          1,
          3.2,
          5.4,
          7.6,
          9.8
         ],
         "y": [
          1,
          3.2,
          5.4,
          7.6,
          9.8
         ]
        },
        {
         "error_y": {
          "array": [
           1,
           2,
           3,
           4,
           5
          ],
          "type": "data",
          "visible": true
         },
         "marker": {
          "color": [
           1,
           2,
           3,
           4,
           5
          ],
          "showscale": true,
          "size": 90
         },
         "mode": "markers",
         "name": "layer width: 400",
         "type": "scatter",
         "x": [
          1,
          3.2,
          5.4,
          7.6,
          9.8
         ],
         "y": [
          1,
          3.2,
          5.4,
          7.6,
          9.8
         ]
        }
       ],
       "layout": {
        "legend": {
         "x": 0.01,
         "xanchor": "left",
         "y": 0.99,
         "yanchor": "top"
        },
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = go.Figure()\n",
    "\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=[1, 3.2, 5.4, 7.6, 9.8],\n",
    "    y=[1, 3.2, 5.4, 7.6, 9.8],\n",
    "    mode='markers',\n",
    "    marker=dict(\n",
    "        color=[1, 2, 3, 4, 5],\n",
    "        size=30,\n",
    "        showscale=True\n",
    "        ),\n",
    "    error_y=dict(\n",
    "            type='data', # value of error bar given in data coordinates\n",
    "            array=[1, 2, 3, 4, 5],\n",
    "            visible=True),\n",
    "    name='layer width: 50'\n",
    "))\n",
    "\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=[1, 3.2, 5.4, 7.6, 9.8],\n",
    "    y=[1, 3.2, 5.4, 7.6, 9.8],\n",
    "    mode='markers',\n",
    "    marker=dict(\n",
    "        color=[1, 2, 3, 4, 5],\n",
    "        size=55,\n",
    "        showscale=True\n",
    "        ),\n",
    "    error_y=dict(\n",
    "            type='data', # value of error bar given in data coordinates\n",
    "            array=[1, 2, 3, 4, 5],\n",
    "            visible=True),\n",
    "    name='layer width: 100'\n",
    "))\n",
    "\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=[1, 3.2, 5.4, 7.6, 9.8],\n",
    "    y=[1, 3.2, 5.4, 7.6, 9.8],\n",
    "    mode='markers',\n",
    "    marker=dict(\n",
    "        color=[1, 2, 3, 4, 5],\n",
    "        size=70,\n",
    "        showscale=True\n",
    "        ),\n",
    "    error_y=dict(\n",
    "            type='data', # value of error bar given in data coordinates\n",
    "            array=[1, 2, 3, 4, 5],\n",
    "            visible=True),\n",
    "    name='layer width: 200'\n",
    "))\n",
    "\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=[1, 3.2, 5.4, 7.6, 9.8],\n",
    "    y=[1, 3.2, 5.4, 7.6, 9.8],\n",
    "    mode='markers',\n",
    "    marker=dict(\n",
    "        color=[1, 2, 3, 4, 5],\n",
    "        size=90,\n",
    "        showscale=True\n",
    "        ),\n",
    "    error_y=dict(\n",
    "            type='data', # value of error bar given in data coordinates\n",
    "            array=[1, 2, 3, 4, 5],\n",
    "            visible=True),\n",
    "    name='layer width: 400'\n",
    "))\n",
    "\n",
    "fig.update_layout(legend=dict(\n",
    "    yanchor=\"top\",\n",
    "    y=0.99,\n",
    "    xanchor=\"left\",\n",
    "    x=0.01\n",
    "))\n",
    "\n",
    "fig.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e13549091eeb6d212316983f0d9bb375e4ef3e549472c705cc2bde65fe2521f7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
